{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "extension_one.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d6e5eefd7da44c309d7aa1b3790ce0ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_05931a9d2459433f8aea0e6e382c75e9",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_77777aec1f534c6ca4d3d64bef764765",
              "IPY_MODEL_44929a54b15140a7845919035ecaca29"
            ]
          }
        },
        "05931a9d2459433f8aea0e6e382c75e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "77777aec1f534c6ca4d3d64bef764765": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5866eb5314d84af99d258227f438e28f",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 456,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 456,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_14280b6126f042ab93d085f483e9a733"
          }
        },
        "44929a54b15140a7845919035ecaca29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ef9e5a6826b942a29839a4f4f21c228b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 456/456 [00:02&lt;00:00, 170B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b8b2fb8a56e74477aa4fb1dc2a374e77"
          }
        },
        "5866eb5314d84af99d258227f438e28f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "14280b6126f042ab93d085f483e9a733": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ef9e5a6826b942a29839a4f4f21c228b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b8b2fb8a56e74477aa4fb1dc2a374e77": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ef4a62e8acab4dc5909630224adf6b15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a63d0193e7de4606b3f0f1d368015e7c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8d5422cb845749ea9d9a79d035fd1c42",
              "IPY_MODEL_9fc72d83787148698f675743ce080ce8"
            ]
          }
        },
        "a63d0193e7de4606b3f0f1d368015e7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8d5422cb845749ea9d9a79d035fd1c42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ab8c8609cb764cb0ae6f37d367fe2db9",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 242120,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 242120,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d531b6a870c64672a0a67fef33a30f80"
          }
        },
        "9fc72d83787148698f675743ce080ce8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7039286ffe414b779729c2b046cdb75a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 242k/242k [00:00&lt;00:00, 309kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9510e279a1b74cf78b6f6a563d695451"
          }
        },
        "ab8c8609cb764cb0ae6f37d367fe2db9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d531b6a870c64672a0a67fef33a30f80": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7039286ffe414b779729c2b046cdb75a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9510e279a1b74cf78b6f6a563d695451": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "05610ee41e844706af033082922b0315": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_babdeadceedf4839b76e580a2415a1d6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_cb8b34dc36b7472aaab4be5c059fe797",
              "IPY_MODEL_7bf1792a500547a296f775fdaa554dd4"
            ]
          }
        },
        "babdeadceedf4839b76e580a2415a1d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cb8b34dc36b7472aaab4be5c059fe797": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_282ff61b46444d4abab8c9ba8582fb03",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 2,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 2,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_71aaedca81a54b96870437bb0699dccf"
          }
        },
        "7bf1792a500547a296f775fdaa554dd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_53d34f510fa94187ad6ff75713c7cbbc",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2.00/2.00 [00:01&lt;00:00, 1.61B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d1ec39f602a54752870e5b9fde782694"
          }
        },
        "282ff61b46444d4abab8c9ba8582fb03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "71aaedca81a54b96870437bb0699dccf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "53d34f510fa94187ad6ff75713c7cbbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d1ec39f602a54752870e5b9fde782694": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f9a6466a0bd9480cadb352f50b488ebd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a496a6b207624918b23964aeb0d2e46f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_bff674e64f39459c9bd7056da3fea999",
              "IPY_MODEL_3f313139506d486eb44fe66e8fe1664d"
            ]
          }
        },
        "a496a6b207624918b23964aeb0d2e46f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bff674e64f39459c9bd7056da3fea999": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a166639498254a0096b0a97efab3c90e",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 112,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 112,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bab84f02030a4aa8ba65782dcb230eff"
          }
        },
        "3f313139506d486eb44fe66e8fe1664d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_15f316de2a4e4748be29c9de332a6b7a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 112/112 [00:00&lt;00:00, 183B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_56162fd2e6a8401e829805af3684d1dd"
          }
        },
        "a166639498254a0096b0a97efab3c90e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bab84f02030a4aa8ba65782dcb230eff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "15f316de2a4e4748be29c9de332a6b7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "56162fd2e6a8401e829805af3684d1dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a71ae6d40a724547930b65aaac3037e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_740f65023c784446be2072887adb987a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_babd49b440b84c1abab500820e69da24",
              "IPY_MODEL_55a1d4a07d834164848ce080aaf52133"
            ]
          }
        },
        "740f65023c784446be2072887adb987a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "babd49b440b84c1abab500820e69da24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_98ae43180aed409d891a51baf3f35a3d",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 43,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 43,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2b02913f166e461b8692cffd4fcd1179"
          }
        },
        "55a1d4a07d834164848ce080aaf52133": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3449d98720d44cc9a5c09604bcd166b2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 43.0/43.0 [00:00&lt;00:00, 874B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_77b129b56262479b94ca69c959f534fe"
          }
        },
        "98ae43180aed409d891a51baf3f35a3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2b02913f166e461b8692cffd4fcd1179": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3449d98720d44cc9a5c09604bcd166b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "77b129b56262479b94ca69c959f534fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1e50cf3f16bc4891804a0f955962e8d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6760fdf23d2248f997a29122f18b38dc",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_12b3600c8316420984521bef18254fd1",
              "IPY_MODEL_b026f158fd9b4ce4827dd5a654095a42"
            ]
          }
        },
        "6760fdf23d2248f997a29122f18b38dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "12b3600c8316420984521bef18254fd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3606cd7e888044de9487057d95a8c771",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 441944381,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 441944381,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cf72a6ff5b0549c1b87c478f987ae95e"
          }
        },
        "b026f158fd9b4ce4827dd5a654095a42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_dd24e58d02384c81b13059568048988a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 442M/442M [00:13&lt;00:00, 33.8MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ddc70706596247fe9eef776e73c46311"
          }
        },
        "3606cd7e888044de9487057d95a8c771": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cf72a6ff5b0549c1b87c478f987ae95e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dd24e58d02384c81b13059568048988a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ddc70706596247fe9eef776e73c46311": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJWDq-8og-mX",
        "colab_type": "text"
      },
      "source": [
        "# pytorch setup, imports and constants initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bx60HT3t1LM-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !pip uninstall tensorflow --yes\n",
        "# !pip uninstall tensorboard --yes\n",
        "# !pip install --ignore-installed tf-nightly"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYAFESqjg8fM",
        "colab_type": "code",
        "outputId": "2c92de42-c9b2-4ade-8ee6-c13448e75b2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        }
      },
      "source": [
        "import os\n",
        "from os.path import exists\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "!pip3 install https://download.pytorch.org/whl/cu100/torch-1.0.1-cp36-cp36m-linux_x86_64.whl\n",
        "!pip3 install torch torchvision\n",
        "  \n",
        "import torch\n",
        "device =  torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch==1.0.1\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu100/torch-1.0.1-cp36-cp36m-linux_x86_64.whl (614.8MB)\n",
            "\u001b[K     |████████████████████████████████| 614.8MB 29kB/s \n",
            "\u001b[31mERROR: torchvision 0.6.0+cu101 has requirement torch==1.5.0, but you'll have torch 1.0.1 which is incompatible.\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch\n",
            "  Found existing installation: torch 1.5.0+cu101\n",
            "    Uninstalling torch-1.5.0+cu101:\n",
            "      Successfully uninstalled torch-1.5.0+cu101\n",
            "Successfully installed torch-1.0.1\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.0.1)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.6.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.18.3)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (7.0.0)\n",
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NK4-jWrThJd5",
        "colab_type": "code",
        "outputId": "872eb255-5944-485b-b652-8618e7242994",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "!pip3 install pymagnitude\n",
        "from pymagnitude import *\n",
        "\n",
        "import time\n",
        "import argparse\n",
        "import numpy as np\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "from torch import optim\n",
        "from torch.nn.utils.rnn import pad_packed_sequence, pack_padded_sequence\n",
        "from sklearn.metrics import f1_score\n",
        "from pdb import set_trace as debug\n",
        "import pickle\n",
        "\n",
        "\n",
        "PAD = 0\n",
        "UNK = 1\n",
        "BOS = 2\n",
        "EOS = 3\n",
        "\n",
        "PAD_WORD = '<blank>'\n",
        "UNK_WORD = '<unk>'\n",
        "BOS_WORD = '<s>'\n",
        "EOS_WORD = '</s>'\n",
        "\n",
        "CAT = ['PER', 'ORG', 'LOC', 'MISC']\n",
        "POSITION = ['I', 'B']\n",
        "LABEL_INDEX = [PAD_WORD] + ['O'] + [\"{}-{}\".format(position, cat) for cat in CAT for position in POSITION]"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pymagnitude\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0a/a3/b9a34d22ed8c0ed59b00ff55092129641cdfa09d82f9abdc5088051a5b0c/pymagnitude-0.1.120.tar.gz (5.4MB)\n",
            "\u001b[K     |████████████████████████████████| 5.4MB 4.0MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pymagnitude\n",
            "  Building wheel for pymagnitude (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pymagnitude: filename=pymagnitude-0.1.120-cp36-cp36m-linux_x86_64.whl size=135918206 sha256=2eebdfccd9b6d96ef7c6755f8408b0e320ae300cd4f19896b2b4bf472355710b\n",
            "  Stored in directory: /root/.cache/pip/wheels/a2/c7/98/cb48b9db35f8d1a7827b764dc36c5515179dc116448a47c8a1\n",
            "Successfully built pymagnitude\n",
            "Installing collected packages: pymagnitude\n",
            "Successfully installed pymagnitude-0.1.120\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vvgAcjm6hyiH",
        "colab_type": "text"
      },
      "source": [
        "# Connect to Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YfhNBjSynDh",
        "colab_type": "code",
        "outputId": "6866acd1-74f2-4f88-90d4-50bec112738e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "%cd \"/content/gdrive/Shared drives/CIS 530 Project/\""
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n",
            "/content/gdrive/Shared drives/CIS 530 Project\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sy2KI9Gxtiio",
        "colab_type": "text"
      },
      "source": [
        "# Embeddings from Transformer models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-JpVDSyaGSj8",
        "colab_type": "text"
      },
      "source": [
        "##BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYITTxC4gT3t",
        "colab_type": "code",
        "outputId": "2887451c-0cbc-47ce-baf0-9e87b03661ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "def load_obj(name ):\n",
        "  with open('obj/' + name + '.pkl', 'rb') as f:\n",
        "    return pickle.load(f)\n",
        "\n",
        "# Returns a tuple (numpy matrix, word_to_index dict) where the matrix contains all the \n",
        "# X-dimensional word embeddings, and word_to_index is a dictionary from the\n",
        "# word into the index in the matrix. For Out-of-vocabulary words it uses\n",
        "# a [UNK] or <unused> embedding\n",
        "def get_indexed_mbert_word_embeddings():\n",
        "  loaded_list = load_obj('mbert_matrix_v2')\n",
        "  loaded_np_matrix = np.asarray(loaded_list)\n",
        "  loaded_word_to_idx = load_obj('mbert_word_to_index_v2')\n",
        "  return loaded_np_matrix, loaded_word_to_idx \n",
        "\n",
        "mat, idx = get_indexed_mbert_word_embeddings()\n",
        "# embed = mat[idx.get('cat')]\n",
        "print(len(idx))\n",
        "# print(type(embed))\n",
        "# print(embed.shape)\n",
        "print(mat.shape)\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "69439\n",
            "(69438, 768)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGACLiBXofNq",
        "colab_type": "text"
      },
      "source": [
        "## BETO"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSayKr9gogk4",
        "colab_type": "code",
        "outputId": "ec4b1cea-7bdf-479b-975e-dd45f0eee692",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 948,
          "referenced_widgets": [
            "d6e5eefd7da44c309d7aa1b3790ce0ad",
            "05931a9d2459433f8aea0e6e382c75e9",
            "77777aec1f534c6ca4d3d64bef764765",
            "44929a54b15140a7845919035ecaca29",
            "5866eb5314d84af99d258227f438e28f",
            "14280b6126f042ab93d085f483e9a733",
            "ef9e5a6826b942a29839a4f4f21c228b",
            "b8b2fb8a56e74477aa4fb1dc2a374e77",
            "ef4a62e8acab4dc5909630224adf6b15",
            "a63d0193e7de4606b3f0f1d368015e7c",
            "8d5422cb845749ea9d9a79d035fd1c42",
            "9fc72d83787148698f675743ce080ce8",
            "ab8c8609cb764cb0ae6f37d367fe2db9",
            "d531b6a870c64672a0a67fef33a30f80",
            "7039286ffe414b779729c2b046cdb75a",
            "9510e279a1b74cf78b6f6a563d695451",
            "05610ee41e844706af033082922b0315",
            "babdeadceedf4839b76e580a2415a1d6",
            "cb8b34dc36b7472aaab4be5c059fe797",
            "7bf1792a500547a296f775fdaa554dd4",
            "282ff61b46444d4abab8c9ba8582fb03",
            "71aaedca81a54b96870437bb0699dccf",
            "53d34f510fa94187ad6ff75713c7cbbc",
            "d1ec39f602a54752870e5b9fde782694",
            "f9a6466a0bd9480cadb352f50b488ebd",
            "a496a6b207624918b23964aeb0d2e46f",
            "bff674e64f39459c9bd7056da3fea999",
            "3f313139506d486eb44fe66e8fe1664d",
            "a166639498254a0096b0a97efab3c90e",
            "bab84f02030a4aa8ba65782dcb230eff",
            "15f316de2a4e4748be29c9de332a6b7a",
            "56162fd2e6a8401e829805af3684d1dd",
            "a71ae6d40a724547930b65aaac3037e5",
            "740f65023c784446be2072887adb987a",
            "babd49b440b84c1abab500820e69da24",
            "55a1d4a07d834164848ce080aaf52133",
            "98ae43180aed409d891a51baf3f35a3d",
            "2b02913f166e461b8692cffd4fcd1179",
            "3449d98720d44cc9a5c09604bcd166b2",
            "77b129b56262479b94ca69c959f534fe",
            "1e50cf3f16bc4891804a0f955962e8d9",
            "6760fdf23d2248f997a29122f18b38dc",
            "12b3600c8316420984521bef18254fd1",
            "b026f158fd9b4ce4827dd5a654095a42",
            "3606cd7e888044de9487057d95a8c771",
            "cf72a6ff5b0549c1b87c478f987ae95e",
            "dd24e58d02384c81b13059568048988a",
            "ddc70706596247fe9eef776e73c46311"
          ]
        }
      },
      "source": [
        "!pip3 install transformers\n",
        "# !wget https://users.dcc.uchile.cl/~jperez/beto/cased_2M/pytorch_weights.tar.gz \n",
        "# !wget https://users.dcc.uchile.cl/~jperez/beto/cased_2M/vocab.txt \n",
        "# !wget https://users.dcc.uchile.cl/~jperez/beto/cased_2M/config.json \n",
        "# !tar -xzvf pytorch_weights.tar.gz\n",
        "# !mv config.json pytorch/.\n",
        "# !mv vocab.txt pytorch/.\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelWithLMHead\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"dccuchile/bert-base-spanish-wwm-cased\")\n",
        "model = AutoModelWithLMHead.from_pretrained(\"dccuchile/bert-base-spanish-wwm-cased\")\n",
        "model.eval()\n",
        "model.cuda()\n",
        "\n",
        "# Returns a tuple (numpy matrix, word_to_index dict) where the matrix contains all the \n",
        "# X-dimensional word embeddings, and word_to_index is a dictionary from the\n",
        "# word into the index in the matrix. For Out-of-vocabulary words it uses\n",
        "# a [UNK] or <unused> embedding\n",
        "def get_indexed_beto_word_embeddings():\n",
        "  path = \"pytorch/vocab.txt\"\n",
        "  idx=0\n",
        "  word_to_index = dict()\n",
        "  with open(path, 'r') as f:\n",
        "    for line in f:\n",
        "        line = line.rstrip('\\n').split('\\t')\n",
        "        word_to_index[line[0]] = idx\n",
        "        idx=idx+1 \n",
        "\n",
        "  matrix = model.get_input_embeddings().weight.data\n",
        "  np_matrix = matrix.cpu().numpy()\n",
        "\n",
        "  return np_matrix, word_to_index\n",
        "\n",
        "# mat, word_to_idx = get_indexed_beto_word_embeddings()\n",
        "# print(mat.shape)\n",
        "# embed = mat[word_to_idx.get('para'),3] #default value if word not found is <UNK> or index 3.\n",
        "# print(embed.shape)\n",
        "# print(type(embed))\n",
        "# print(embed)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/78/92cedda05552398352ed9784908b834ee32a0bd071a9b32de287327370b7/transformers-2.8.0-py3-none-any.whl (563kB)\n",
            "\r\u001b[K     |▋                               | 10kB 22.1MB/s eta 0:00:01\r\u001b[K     |█▏                              | 20kB 3.1MB/s eta 0:00:01\r\u001b[K     |█▊                              | 30kB 4.5MB/s eta 0:00:01\r\u001b[K     |██▎                             | 40kB 2.9MB/s eta 0:00:01\r\u001b[K     |███                             | 51kB 3.6MB/s eta 0:00:01\r\u001b[K     |███▌                            | 61kB 4.3MB/s eta 0:00:01\r\u001b[K     |████                            | 71kB 4.9MB/s eta 0:00:01\r\u001b[K     |████▋                           | 81kB 3.8MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 92kB 4.3MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 102kB 4.7MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 112kB 4.7MB/s eta 0:00:01\r\u001b[K     |███████                         | 122kB 4.7MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 133kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 143kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 153kB 4.7MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 163kB 4.7MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 174kB 4.7MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 184kB 4.7MB/s eta 0:00:01\r\u001b[K     |███████████                     | 194kB 4.7MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 204kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 215kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 225kB 4.7MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 235kB 4.7MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 245kB 4.7MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 256kB 4.7MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 266kB 4.7MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 276kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 286kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 296kB 4.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 307kB 4.7MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 317kB 4.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 327kB 4.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 337kB 4.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 348kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 358kB 4.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 368kB 4.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 378kB 4.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 389kB 4.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 399kB 4.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 409kB 4.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 419kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 430kB 4.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 440kB 4.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 450kB 4.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 460kB 4.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 471kB 4.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 481kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 491kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 501kB 4.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 512kB 4.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 522kB 4.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 532kB 4.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 542kB 4.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 552kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 563kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 573kB 4.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/2c/8df20f3ac6c22ac224fff307ebc102818206c53fc454ecd37d8ac2060df5/sentencepiece-0.1.86-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 64.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.12.47)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.3)\n",
            "Collecting tokenizers==0.5.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
            "\u001b[K     |████████████████████████████████| 3.7MB 51.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.38.0)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/50/93509f906a40bffd7d175f97fd75ea328ad9bd91f48f59c4bd084c94a25e/sacremoses-0.0.41.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 65.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.9)\n",
            "Requirement already satisfied: botocore<1.16.0,>=1.15.47 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.15.47)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.5)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.14.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.47->boto3->transformers) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.47->boto3->transformers) (2.8.1)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.41-cp36-none-any.whl size=893334 sha256=9568430559e503ee0c1786ee6fff50a4e2ea74b5752306e2eda52cbf00c558d7\n",
            "  Stored in directory: /root/.cache/pip/wheels/22/5a/d4/b020a81249de7dc63758a34222feaa668dbe8ebfe9170cc9b1\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.41 sentencepiece-0.1.86 tokenizers-0.5.2 transformers-2.8.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d6e5eefd7da44c309d7aa1b3790ce0ad",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=456, style=ProgressStyle(description_width=…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ef4a62e8acab4dc5909630224adf6b15",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=242120, style=ProgressStyle(description_wid…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "05610ee41e844706af033082922b0315",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=2, style=ProgressStyle(description_width='i…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f9a6466a0bd9480cadb352f50b488ebd",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=112, style=ProgressStyle(description_width=…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a71ae6d40a724547930b65aaac3037e5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=43, style=ProgressStyle(description_width='…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1e50cf3f16bc4891804a0f955962e8d9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=441944381, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZxser1ahU72",
        "colab_type": "text"
      },
      "source": [
        "# Utility Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhafrdBfhXZo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Returns the dictionary from the file with translations\n",
        "def english_to_spanish_dict(path):\n",
        "  en_to_spanish = dict()\n",
        "\n",
        "  with open(path, 'r') as f:\n",
        "    for line in f:\n",
        "        line = line.rstrip('\\n').split('\\t')\n",
        "        en_word = line[0]\n",
        "        es_word = line[1]\n",
        "        if en_word.isupper(): en_to_spanish[en_word] = es_word.upper()\n",
        "        elif len(en_word) > 0 and en_word[0].isupper(): en_to_spanish[en_word] = es_word.capitalize()\n",
        "        else: en_to_spanish[en_word] = es_word\n",
        "\n",
        "  return en_to_spanish\n",
        "\n",
        "# Returns a tuple (matrix, word_to_index) where the matrix contains all the \n",
        "# X-dimensional word embeddings, and word_to_index is a dictionary from the\n",
        "# word into the index in the matrix. For Out-of-vocabulary words it creates\n",
        "# a random embedding\n",
        "def get_indexed_word_embeddings(translation_path, embedding_path):\n",
        "  en_to_spanish = english_to_spanish_dict(translation_path)\n",
        "  vectors = Magnitude(embedding_path)\n",
        "\n",
        "  dim = vectors.dim\n",
        "  \n",
        "  matrix = [] # words by embedding-dimension\n",
        "  word_to_index = dict()\n",
        "\n",
        "  index = 0\n",
        "\n",
        "  en_files = ['Data/eng.train', 'Data/eng.testa', 'Data/eng.testb']\n",
        "  \n",
        "  for file in en_files:\n",
        "    with open(file, 'r') as f:\n",
        "      for line in f:\n",
        "        line = line.rstrip('\\n')\n",
        "        if line == \"\": continue\n",
        "\n",
        "        word = line.split()[0]\n",
        "        trans = en_to_spanish[word]\n",
        "        if trans not in word_to_index:\n",
        "          word_to_index[trans] = index\n",
        "          if trans in vectors: matrix.append(vectors.query(trans))\n",
        "          else: matrix.append(np.random.uniform(-(3/dim)**0.5, (3/dim)**0.5, dim))\n",
        "\n",
        "          index += 1\n",
        "\n",
        "  es_files = ['Data/esp.train', 'Data/esp.testa', 'Data/esp.testb']\n",
        "  \n",
        "  for file in es_files:\n",
        "    with open(file, 'r') as f:\n",
        "      for line in f:\n",
        "        line = line.rstrip('\\n')\n",
        "        if line == \"\": continue\n",
        "\n",
        "        word = line.split()[0]\n",
        "        if word not in word_to_index:\n",
        "          word_to_index[word] = index\n",
        "          if word in vectors: matrix.append(vectors.query(word))\n",
        "          else: matrix.append(np.random.uniform(-(3/dim)**0.5, (3/dim)**0.5, dim))\n",
        "            \n",
        "          index += 1\n",
        "\n",
        "  return matrix, word_to_index\n",
        "\n",
        "#returns char dictionary created from all path in paths\n",
        "def create_char_index(paths, es_translation_dict, pad=False): #AS IS\n",
        "    char_dict = {}\n",
        "    if pad:\n",
        "        char_dict[PAD_WORD] = PAD\n",
        "        char_dict[UNK_WORD] = UNK\n",
        "    else:\n",
        "        char_dict[UNK_WORD] = 0\n",
        "\n",
        "    for path in paths:\n",
        "        for line in open(path):\n",
        "            l = line.strip().split()\n",
        "            if len(l) > 0:# and l[0] != '':\n",
        "              #l[0] is word l[1] is POS, l[2] is gold standard NER label\n",
        "              word = l[0]\n",
        "              es_word = word\n",
        "              if word in es_translation_dict:\n",
        "                es_word = es_translation_dict.get(word)\n",
        "              for i in range(len(es_word)):\n",
        "                  if es_word[i] not in char_dict:\n",
        "                      char_dict[es_word[i]] = len(char_dict)\n",
        "\n",
        "    return char_dict\n",
        "\n",
        "#   Returns \n",
        "#1. all the spanish 'sentences' in 2D array\n",
        "#2. 2D array indicating if word in given sentence is OOV word (True if the word is used as-is, translation not found) or not\n",
        "#3. 2D array returning labels.\n",
        "#   in the file(s) at paths in an array.\n",
        "def data_to_words_sentences(paths, es_translation_dict, test=False):\n",
        "  sentences=[]\n",
        "  curr_sentence=[]\n",
        "  OOV = []\n",
        "  labels=[]\n",
        "  curr_OOV_sentence = []\n",
        "  curr_label_sentence = []\n",
        "  word_idx = 0\n",
        "  for path in paths:\n",
        "      for line in open(path):\n",
        "        line = line.strip().split()\n",
        "        \n",
        "        end_of_line=False\n",
        "        if len(line) == 0:\n",
        "          end_of_line=True\n",
        "        \n",
        "        if not end_of_line:\n",
        "          word = line[0]\n",
        "          es_word = word\n",
        "\n",
        "          if not test: #english has 4th column label\n",
        "            curr_label_sentence.append(line[3])\n",
        "          else: #spanish has 3rd column label\n",
        "            curr_label_sentence.append(line[2])\n",
        "\n",
        "          curr_OOV_sentence.append(True)\n",
        "          if test:\n",
        "            curr_OOV_sentence[word_idx] = False\n",
        "          else: #not test\n",
        "            if word in es_translation_dict:\n",
        "              es_word = es_translation_dict.get(word)\n",
        "              curr_OOV_sentence[word_idx] = False\n",
        "          \n",
        "          word_idx = word_idx+1\n",
        "          curr_sentence.append(es_word)\n",
        "        if end_of_line:\n",
        "          sentences.append(curr_sentence)\n",
        "          OOV.append(curr_OOV_sentence)\n",
        "          labels.append(curr_label_sentence)\n",
        "          curr_sentence=[]\n",
        "          curr_OOV_sentence=[]\n",
        "          curr_label_sentence=[]\n",
        "          word_idx=0\n",
        "  return sentences, OOV, labels\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TeSYLEOZx4jr",
        "colab_type": "text"
      },
      "source": [
        "##Get_input fucntion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmzyybTXx3B8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#ADD all methods to get initial input to neural network here. Returns char, labels and word input\n",
        "#OOV[i] indicates if word[i] is OOV (translation not found)\n",
        "def get_input(transformer_word_vocab_dict, word_vocab_dict, sentences, OOV, char_vocab_dict, token_labels, label_to_index):\n",
        "  max_word_len = max(len(word) for sentence in sentences for word in sentence)\n",
        "  #max_word_len = max(len(word) for word in words)\n",
        "  max_sentence_length = max(len(sentence) for sentence in sentences)\n",
        "\n",
        "  word_input = np.zeros((len(sentences), max_sentence_length), dtype='int64')\n",
        "  word_input_length = [len(sentence) for sentence in sentences]\n",
        "\n",
        "  char_input = np.zeros((len(sentences), max_sentence_length,max_word_len), dtype='int64') \n",
        "  char_input_length = np.zeros((len(sentences), max_sentence_length), dtype='int64') #2D array of length of word in each sentence in sentences\n",
        "  \n",
        "  # word_mbert_input = get_mbert_es_embeddings(sentences, max_sentence_length)\n",
        "  transformer_word_input = np.zeros((len(sentences), max_sentence_length), dtype='int64')\n",
        "\n",
        "\n",
        "  label_input = np.zeros((len(sentences), max_sentence_length), dtype='int64') #2D array of label of word in each sentence in sentences\n",
        "  for i in range(len(sentences)):\n",
        "    for j in range(len(sentences[i])):\n",
        "      word_input[i][j] = word_vocab_dict[sentences[i][j]]\n",
        "      transformer_word_input[i][j] = transformer_word_vocab_dict[sentences[i][j]]\n",
        "\n",
        "      char_input_length[i][j] = len(sentences[i][j]) \n",
        "      label_input[i][j] = label_to_index.index(token_labels[i][j])\n",
        "\n",
        "      for k in range(len(sentences[i][j])):\n",
        "        c = sentences[i][j][k]\n",
        "        if c in char_vocab_dict:\n",
        "          input_zero = c.isdigit() or OOV[i][j]\n",
        "          char_input[i][j][k] = char_vocab_dict['0' if input_zero else c]\n",
        "        else:\n",
        "          char_input[i][j][k] = UNK\n",
        "\n",
        "  word_input_var = Variable(torch.from_numpy(word_input), requires_grad=False)\n",
        "  transformer_word_input_var = Variable(torch.from_numpy(transformer_word_input), requires_grad=False)\n",
        "  word_input_length_var = Variable(torch.LongTensor(word_input_length), requires_grad=False)\n",
        "  label_var = Variable(torch.from_numpy(label_input), requires_grad=False)\n",
        "  char_input_var = Variable(torch.from_numpy(char_input), requires_grad=False)\n",
        "  char_input_length_var = Variable(torch.from_numpy(char_input_length), requires_grad=False)\n",
        "  return transformer_word_input_var.cuda(), word_input_var.cuda(), word_input_length_var.cuda(), char_input_var.cuda(), char_input_length_var.cuda(), label_var.cuda()\n",
        "\n",
        "def batch_from_data(X, X1, y, batch_size, random=True):\n",
        "    batch_num = int(np.ceil(len(y) / float(batch_size)))\n",
        "    rand_indices = np.arange(len(y))\n",
        "    if random: rand_indices = np.random.permutation(len(y))\n",
        "\n",
        "    for batch in range(0, batch_num):\n",
        "        bs = batch_size if batch < batch_num - 1 else len(y) - batch_size * batch\n",
        "        #from pdb import set_trace as debug\n",
        "        #debug()\n",
        "        yield [X[i] for i in rand_indices[batch * batch_size : batch * batch_size + bs]], [X1[i] for i in rand_indices[batch * batch_size : batch * batch_size + bs]], [y[i] for i in rand_indices[batch * batch_size : batch * batch_size + bs]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpY4fK3phkHJ",
        "colab_type": "text"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzIbKaR0bph_",
        "colab_type": "text"
      },
      "source": [
        "##char embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPyhlkQQhmfg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class char_model(nn.Module):\n",
        "    def __init__(self, char_vocab_size, char_embed_size, char_lstm_hidden_size=50):\n",
        "\n",
        "        #START: char embedding section\n",
        "        super(char_model, self).__init__()\n",
        "        self.char_embed = nn.Embedding(char_vocab_size, char_embed_size, padding_idx=PAD)\n",
        "        self.char_lstm = nn.LSTM(char_embed_size, char_lstm_hidden_size, bidirectional=True, batch_first=True)\n",
        "        self.char_lstm_hidden_size = char_lstm_hidden_size\n",
        "        #END: char embedding section \n",
        "\n",
        "    def forward(self, char_inp, char_input_length):\n",
        "\n",
        "        #START: char embedding section\n",
        "        #from pdb import set_trace as debug\n",
        "        #debug()\n",
        "        char_input = char_inp.view(-1, char_inp.size(2))\n",
        "        char_input_length_sorted, char_original_idx = char_input_length.view(-1).sort(0, descending=True)\n",
        "        char_embedded = self.char_embed(char_input)\n",
        "        char_embedded_sorted = char_embedded[char_original_idx] #get embeddings in descending order of length of word in words\n",
        "\n",
        "        char_input_length_sorted_size = char_input_length_sorted.size(0)\n",
        "        last_index = char_input_length_sorted_size\n",
        "        if char_input_length_sorted.data.eq(0).sum() != 0: #atleast 1 element of char_input_length_sorted is/are zero\n",
        "          last_index = char_input_length_sorted.data.eq(0).nonzero()[0][0]\n",
        "        char_embedded_sorted = char_embedded_sorted[:last_index]\n",
        "        char_input_length_sorted = char_input_length_sorted[:last_index]\n",
        "\n",
        "        char_input_packed_padded = pack_padded_sequence(char_embedded_sorted, char_input_length_sorted.cpu().data.numpy(), batch_first=True)\n",
        "        char_output_packed_padded, (h_n, c_n) = self.char_lstm(char_input_packed_padded)\n",
        "        char_hidden_state = torch.cat([h_n[0], h_n[1]], 1)\n",
        "\n",
        "        if last_index != char_input_length_sorted_size:\n",
        "          zero_padding_diff = char_input_length_sorted_size - last_index\n",
        "          zero_padding = Variable(torch.zeros((zero_padding_diff, 2*self.char_lstm_hidden_size)), requires_grad=False).cuda()\n",
        "          char_hidden_state = torch.cat([char_hidden_state, zero_padding], 0)\n",
        "\n",
        "        char_hidden_state = char_hidden_state[torch.argsort(char_original_idx)] #char_hidden_state[torch.from_numpy(np.argsort(char_original_idx.cpu().data.numpy())).cuda()]\n",
        "        char_hidden_state = char_hidden_state.view(char_inp.size(0), -1, char_hidden_state.size(1))\n",
        "        return char_hidden_state\n",
        "        #END: char embedding section \n",
        "\n",
        "    def reset_parameters(self):\n",
        "\n",
        "      #START: char embedding section\n",
        "      for param in self.char_embed.parameters():\n",
        "          nn.init.normal(param, mean=0, std=0.01)\n",
        "\n",
        "      for name, param in self.char_lstm.named_parameters():\n",
        "          if 'bias' in name:\n",
        "              nn.init.constant_(param, 0.)\n",
        "          elif 'weight' in name:\n",
        "              nn.init.normal(param, mean=0, std=0.1)\n",
        "      #END: char embedding section "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DY26JE0ebtmV",
        "colab_type": "text"
      },
      "source": [
        "##Self Attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evmwaqT6-fal",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class selfAttention(nn.Module):\n",
        "\n",
        "  def __init__(self, transformer_hidden_size, transformer_matrix, char_lstm_hidden_size, word_vocab_size, word_embedding_size, word_lstm_hiddden_size, word_vector):\n",
        "    super(selfAttention, self).__init__()\n",
        "    self.word_embed = nn.Embedding(word_vocab_size, word_embedding_size, padding_idx=PAD)\n",
        "    self.transformer_matrix = transformer_matrix\n",
        "    self.transformer_hidden_size = transformer_hidden_size\n",
        "\n",
        "    self.word_lstm = nn.LSTM(2*char_lstm_hidden_size + word_embedding_size + transformer_hidden_size, word_lstm_hiddden_size, batch_first=True, bidirectional=True)\n",
        "    self.word_linear = nn.Linear(word_lstm_hiddden_size * 2, word_lstm_hiddden_size * 2)\n",
        "\n",
        "    self.tanh = nn.Tanh()\n",
        "    self.softmax = nn.Softmax(dim=2)\n",
        "    self.embedding_dropout = nn.Dropout(0.5)\n",
        "    self.word_dropout = nn.Dropout(0.5)\n",
        "    self.att_sm_dropout = nn.Dropout(0.5)\n",
        "    #self.att_dropout= nn.Dropout(0.2)\n",
        "    self.word_embed.weight.data.copy_(torch.from_numpy(np.asarray(word_vector)))\n",
        "\n",
        "\n",
        "  def forward(self, transformer_word_input, words, char_hidden_state, word_length):\n",
        "    # word_embedding = self.word_embed(words).cuda()\n",
        "    word_embedding = self.word_embed(words)\n",
        "\n",
        "    transformer_word_embed = (self.TransformerEmbedder(transformer_word_input)).float().cuda()\n",
        "    # debug()\n",
        "    word_lstm_input = torch.cat([transformer_word_embed, word_embedding, char_hidden_state], 2) #here\n",
        "\n",
        "    word_lstm_input = self.embedding_dropout(word_lstm_input)\n",
        "    \n",
        "    word_length, word_idx = word_length.sort(0, descending=True)\n",
        "    word_lstm_input = word_lstm_input[word_idx]\n",
        "\n",
        "    word_packed_input = pack_padded_sequence(word_lstm_input, word_length.cpu().data.numpy(), batch_first=True)\n",
        "    word_packed_output, _ = self.word_lstm(word_packed_input)\n",
        "    word_output, _ = pad_packed_sequence(word_packed_output, batch_first=True)\n",
        "    word_output = word_output[torch.from_numpy(np.argsort(word_idx.cpu().data.numpy())).cuda()]\n",
        "    \n",
        "    word_output = self.word_dropout(word_output)\n",
        "    attn_input = self.tanh(self.word_linear(word_output))\n",
        "\n",
        "    att_padding_mask = Variable(words.data.ne(PAD)).cuda()\n",
        "    context = attn_input * att_padding_mask.float().unsqueeze(2)\n",
        "    attn_out = context.bmm(context.transpose(1, 2))\n",
        "\n",
        "    attention_self_mask = Variable(1 - torch.eye(words.size(1), words.size(1))).cuda()\n",
        "    attn_out = attn_out * attention_self_mask.unsqueeze(0)\n",
        "\n",
        "    out = self.softmax(attn_out)\n",
        "    out = out * att_padding_mask.float().unsqueeze(2)\n",
        "    out = out * att_padding_mask.float().unsqueeze(1)\n",
        "    out = self.att_sm_dropout(out)\n",
        "    context_v = out.bmm(word_output)\n",
        "    #context_v = self.att_dropout(context_v)\n",
        "    word_output = torch.cat([word_output, context_v], 2)\n",
        "\n",
        "    return word_output\n",
        "\n",
        "\n",
        "  def TransformerEmbedder(self, transformer_word_input):\n",
        "    b, s = transformer_word_input.shape # batch, sentence\n",
        "    h = self.transformer_hidden_size # hidden\n",
        "    batch_embed = np.zeros((b, s, h))\n",
        "    # debug()\n",
        "    for i, sentence_as_idx in enumerate(transformer_word_input): # indexing vectorized O(n)\n",
        "      sentence_embed = self.transformer_matrix[sentence_as_idx.cpu()] # sentence_length x embed_hidden_size\n",
        "      batch_embed[i, :, :] = sentence_embed\n",
        "    return torch.from_numpy(batch_embed)\n",
        "\n",
        "\n",
        "  def reset_parameters(self):\n",
        "\n",
        "    for name, param in self.word_lstm.named_parameters():\n",
        "        if 'bias' in name:\n",
        "            nn.init.constant(param, 0.)\n",
        "        elif 'weight' in name:\n",
        "            nn.init.normal(param, mean=0, std=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30gGnBfu_LCp",
        "colab_type": "text"
      },
      "source": [
        "## CRF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNJ_5VGC_GhU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def logsumexp(x, dim=None): #AS IS\n",
        "    if dim is None:\n",
        "        xmax = x.max()\n",
        "        xmax_ = x.max()\n",
        "        return xmax_ + torch.log(torch.exp(x - xmax).sum())\n",
        "    else:\n",
        "        xmax, _ = x.max(dim, keepdim=True)\n",
        "        xmax_, _ = x.max(dim)\n",
        "        return xmax_ + torch.log(torch.exp(x - xmax).sum(dim))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFCLBuPS_Goq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CRF_Module(nn.Module):\n",
        "    def __init__(self, input_size, num_labels, bigram=True):\n",
        "\n",
        "\n",
        "        super(CRF_Module, self).__init__()\n",
        "        self.pad_label_id = num_labels\n",
        "        self.bigram = bigram\n",
        "        self.input_size = input_size\n",
        "        self.num_labels = num_labels + 1\n",
        "        self.state_layer = nn.Linear(input_size, self.num_labels)\n",
        "\n",
        "        if bigram: # \n",
        "            self.transition_layer = nn.Linear(input_size, self.num_labels * self.num_labels) # transition weights are learned (costs of moving from one tag to next)\n",
        "            self.register_parameter('transition_matrix', None)\n",
        "        else:\n",
        "            self.transition_layer = None\n",
        "            self.transition_matrix = Parameter(torch.Tensor(self.num_labels, self.num_labels)) # initialize a transition matrix instead \n",
        "\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def forward(self, input, mask=None):\n",
        "      batch, length, _ = input.size()\n",
        "      out_state = self.state_layer(input).unsqueeze(2)\n",
        "\n",
        "      if self.bigram:\n",
        "          out_transition = self.transition_layer(input).view(batch, length, self.num_labels, self.num_labels)\n",
        "          net_output = out_transition + out_state\n",
        "      else:\n",
        "          net_output = self.transition_matrix + out_state\n",
        "\n",
        "      if mask is not None:\n",
        "          net_output = net_output * mask.unsqueeze(2).unsqueeze(3)\n",
        "      return net_output\n",
        "\n",
        "\n",
        "    def reset_parameters(self):\n",
        "      nn.init.constant(self.state_layer.bias, 0.)\n",
        "      if self.bigram:\n",
        "          nn.init.xavier_uniform(self.transition_layer.weight)\n",
        "          nn.init.constant(self.transition_layer.bias, 0.)\n",
        "      else:\n",
        "          nn.init.normal(self.transition_matrix)\n",
        "\n",
        "\n",
        "    def _viterbi_decode(self, input, mask, leading_symbolic=0):\n",
        "      energy = self.forward(input, mask=mask).data\n",
        "      energyTrans = energy.transpose(0, 1) #energy_transpose\n",
        "      energyTrans = energyTrans[:, :, leading_symbolic:-1, leading_symbolic:-1]\n",
        "\n",
        "      w_len, batch_size, num_label, _ = energyTrans.size()\n",
        "      batch_index = torch.arange(0, batch_size).long().cuda()\n",
        "      \n",
        "      curr_mat = torch.zeros([w_len, batch_size, num_label, 1]).cuda()\n",
        "      pointer = torch.cuda.LongTensor(w_len, batch_size, num_label).zero_()\n",
        "      back_pointer = torch.cuda.LongTensor(w_len, batch_size).zero_()\n",
        "\n",
        "      curr_mat[0] = energy[:, 0, -1, leading_symbolic:-1].unsqueeze(2)\n",
        "      pointer[0] = -1\n",
        "      for t in range(1, w_len):\n",
        "          prev_mat = curr_mat[t - 1]\n",
        "          temp_mat, pointer[t] = torch.max(energyTrans[t] + prev_mat, dim=1)\n",
        "          curr_mat[t] = temp_mat.unsqueeze(2)\n",
        "\n",
        "      _, back_pointer[-1] = torch.max(curr_mat[-1].squeeze(2), dim=1)\n",
        "      for t in reversed(range(w_len - 1)):\n",
        "          pointer_last = pointer[t + 1]\n",
        "          back_pointer[t] = pointer_last[batch_index, back_pointer[t + 1]]\n",
        "\n",
        "      return back_pointer.transpose(0, 1) + leading_symbolic\n",
        "\n",
        "    \n",
        "    def loss(self, input, target, mask=None):\n",
        "      #debug()\n",
        "      batch, length, _ = input.size()\n",
        "      energy = self.forward(input, mask=mask)\n",
        "      energy_transpose = energy.transpose(0, 1)\n",
        "      target_transpose = target.transpose(0, 1)\n",
        "      mask_transpose = None\n",
        "      if mask is not None:\n",
        "          mask_transpose = mask.unsqueeze(2).transpose(0, 1)\n",
        "\n",
        "      partition = None\n",
        "\n",
        "      batch_index = torch.arange(0, batch).long().cuda()\n",
        "      prev_label = torch.cuda.LongTensor(batch).fill_(self.num_labels - 1)\n",
        "      tgt_energy = Variable(torch.zeros(batch)).cuda()\n",
        "\n",
        "      for t in range(length):\n",
        "          curr_energy = energy_transpose[t]\n",
        "          if t == 0:\n",
        "              partition = curr_energy[:, -1, :]\n",
        "          else:\n",
        "              partition_new = logsumexp(curr_energy + partition.unsqueeze(2), dim=1)\n",
        "              if mask_transpose is None:\n",
        "                  partition = partition_new\n",
        "              else:\n",
        "                  mask_t = mask_transpose[t]\n",
        "                  partition = partition + (partition_new - partition) * mask_t\n",
        "          tgt_energy += curr_energy[batch_index, prev_label, target_transpose[t].data]\n",
        "          prev_label = target_transpose[t].data\n",
        "\n",
        "      return logsumexp(partition, dim=1) - tgt_energy\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dV2PGV_qee7p",
        "colab_type": "text"
      },
      "source": [
        "## wrapper code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhRc7_sveiB5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Attention_LSTM_CRF(nn.Module):\n",
        "    def __init__(self, transformer_hidden_size, transformer_matrix, char_vocab_size, char_embed_size, word_vocab_size, word_embedding_size, word_lstm_hiddden_size, word_vector, num_labels, bigram=True, char_lstm_hidden_size=50):\n",
        "        super(Attention_LSTM_CRF, self).__init__()\n",
        "        self.char_vocab_size = char_vocab_size\n",
        "        self.char_embed_size = char_embed_size\n",
        "        self.word_vocab_size = word_vocab_size\n",
        "        self.word_embedding_size = word_embedding_size\n",
        "        self.word_lstm_hiddden_size = word_lstm_hiddden_size\n",
        "        self.char_lstm_hidden_size = char_lstm_hidden_size\n",
        "        self.word_vector = word_vector\n",
        "        self.transformer_matrix = transformer_matrix\n",
        "        self.transformer_hidden_size = transformer_hidden_size\n",
        "\n",
        "        print(\"from hinside\", self.transformer_hidden_size)\n",
        "\n",
        "        # crf vars\n",
        "        self.num_labels = num_labels\n",
        "        self.bigram = bigram\n",
        "\n",
        "        self.charModel = char_model(self.char_vocab_size, self.char_embed_size, self.char_lstm_hidden_size)\n",
        "        self.Attention = selfAttention(self.transformer_hidden_size, self.transformer_matrix, self.char_lstm_hidden_size, self.word_vocab_size, self.word_embedding_size, self.word_lstm_hiddden_size, self.word_vector)\n",
        "        self.CRF = CRF_Module(self.word_lstm_hiddden_size*4, num_labels)\n",
        "    \n",
        "    def forward(self, transfer_word_input, words, input, word_length, char_input_length, target, hidden=None):\n",
        "        charOut = self.charModel(input, char_input_length) #basically char_hidden_state\n",
        "        AttentionOut = self.Attention(transfer_word_input, words, charOut, word_length)\n",
        "        CRFLossOut = self.CRF.loss(AttentionOut, target, words.ne(PAD).float()).mean()\n",
        "        CRFPredict = self.CRF._viterbi_decode(AttentionOut, words.ne(PAD).float(), 1)\n",
        "\n",
        "        return CRFLossOut, CRFPredict\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_Cf3Dq9QyRZ",
        "colab_type": "text"
      },
      "source": [
        "##Training and Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vgUnBcRlkOp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def training(model_save_file, trans_word_vocab_dict, es_translation_dict , char_vocab_dict, model, optimizer, lr, epochs):\n",
        "  best_f1_score = 0.0\n",
        "  \n",
        "  all_train_loss = []\n",
        "  all_val_loss = []\n",
        "  all_train_acc = []\n",
        "  all_val_acc = []\n",
        "  all_train_f1 = []\n",
        "  all_val_f1 = []\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "      labels_global = []\n",
        "      pred_global = []\n",
        "\n",
        "      model.train()\n",
        "\n",
        "      epoch_loss = 0\n",
        "      total = 0\n",
        "      correct = 0\n",
        "      batch =0\n",
        "      \n",
        "      \n",
        "      #es_translation_dict = english_to_spanish_dict(\"translation_bi.txt\")      \n",
        "      train_paths = ['Data/eng.train', 'Data/eng.testa', 'Data/eng.testb']\n",
        "      #char_vocab_dict = create_char_index(train_paths, es_translation_dict, pad=False)\n",
        "      sentences, OOV, labels = data_to_words_sentences(train_paths, es_translation_dict, test=False) #whole data\n",
        "      #train_X = [words, OOV]\n",
        "      \n",
        "      for data in batch_from_data(sentences, OOV, labels, 16):\n",
        "\n",
        "          bsentences, bOOV, y = data\n",
        "          #label_input\n",
        "          \n",
        "          #[bsentences, bOOV] = X\n",
        "          transformer_word_input, word_input, word_length_input, char_input, char_length_input, label_input = get_input(trans_word_vocab_dict, word_to_index, bsentences, bOOV, char_vocab_dict, y, LABEL_INDEX)\n",
        "          optimizer.zero_grad()\n",
        "          true_labels = label_input.contiguous().view(-1)\n",
        "\n",
        "          #forward\n",
        "          loss, predict = model(transformer_word_input, word_input, char_input, word_length_input, char_length_input, label_input)\n",
        "          predict = predict.contiguous().view(-1)\n",
        "\n",
        "          total +=  true_labels.data.ne(PAD).float().sum()\n",
        "          pred_correct = predict.eq(true_labels.data).masked_select(true_labels.ne(PAD).data).float().sum()\n",
        "\n",
        "          loss.backward()\n",
        "          torch.nn.utils.clip_grad_norm(model.parameters(), 5)\n",
        "          optimizer.step()\n",
        "\n",
        "          epoch_loss += loss.item()\n",
        "          correct += pred_correct\n",
        "          batch+=1\n",
        "\n",
        "          labels_global.extend(true_labels.masked_select(true_labels.ne(PAD).data).cpu().data.numpy())\n",
        "          pred_global.extend(predict.masked_select(true_labels.ne(PAD).data).cpu().data.numpy())\n",
        "          \n",
        "          # true_labels_list = list(true_labels.masked_select(true_labels.ne(PAD).data).cpu().data.numpy())\n",
        "          # predict = list(predict.masked_select(true_labels.ne(PAD).data).cpu().data.numpy())\n",
        "          # bsentences = [j for i in bsentences for j in i]\n",
        "          # for i in range(len(bsentences)):\n",
        "          #   print(bsentences[i] + \"\\t\" + LABEL_INDEX[true_labels_list[i]] + \"\\t\" + LABEL_INDEX[predict[i]])\n",
        "\n",
        "          if batch%200==0:\n",
        "            print(\"Batch {} loss: {:.2f}\".format(batch, epoch_loss/batch))\n",
        "    \n",
        "      f1 = f1_score(labels_global, pred_global, average='macro')\n",
        "      \n",
        "      print(\"Epoch {} training loss: {:.4f}, training accuracy: {:.4f}, f1 score {:.2f}\".format(epoch, epoch_loss/batch, correct * 100.0/total, f1))\n",
        "\n",
        "      all_train_loss.append(epoch_loss/batch)\n",
        "      all_train_acc.append(correct * 100.0/total)\n",
        "      all_train_f1.append(f1)\n",
        "\n",
        "      lr = lr / (1.0 + epoch * 0.05) #decay=0.05\n",
        "      for param_group in optimizer.param_groups:\n",
        "          param_group['lr'] = lr\n",
        "      val_f1, val_loss, val_acc = evaluate(trans_word_vocab_dict, es_translation_dict , char_vocab_dict, model) # changed signature\n",
        "\n",
        "      all_val_f1.append(val_f1)\n",
        "      all_val_acc.append(val_acc)\n",
        "      all_val_loss.append(val_loss)\n",
        "\n",
        "      # store at best f1\n",
        "      if val_f1 > best_f1_score :\n",
        "        best_f1_score = val_f1\n",
        "        print(\"Saving model on best val F1 so far \" + str(val_f1))\n",
        "        torch.save(model.state_dict(), model_save_file)\n",
        "\n",
        "  return  all_train_loss, all_val_loss , all_train_acc, all_val_acc , all_train_f1 , all_val_f1\n",
        "\n",
        "\n",
        "def evaluate(trans_word_vocab_dict, es_translation_dict , char_vocab_dict, model):\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    test_loss = 0\n",
        "    batch = 0\n",
        "\n",
        "    labels_global = []\n",
        "    pred_global = []\n",
        "\n",
        "    #es_translation_dict = english_to_spanish_dict(\"translation_bi.txt\")      \n",
        "    val_paths = ['Data/esp.testa']\n",
        "    #char_vocab_dict = create_char_index(val_paths, es_translation_dict, pad=False)\n",
        "    sentences, OOV, labels = data_to_words_sentences(val_paths, es_translation_dict, test=True) #whole data\n",
        "\n",
        "    #val_X = [words, OOV]\n",
        "    for data in batch_from_data(sentences, OOV, labels, 16):\n",
        "        \n",
        "        bsentences, bOOV, y = data\n",
        "        #label_input\n",
        "        \n",
        "        #[bsentences, bOOV] = X\n",
        "        \n",
        "        transformer_word_input, word_input, word_length_input, char_input, char_length_input, label_input = get_input(trans_word_vocab_dict, word_to_index, bsentences, bOOV, char_vocab_dict, y, LABEL_INDEX)\n",
        "        loss, predict = model(transformer_word_input, word_input, char_input, word_length_input, char_length_input, label_input)\n",
        "        predict = predict.contiguous().view(-1)\n",
        "        test_loss += loss.item()\n",
        "\n",
        "\n",
        "        true_labels = label_input.contiguous().view(-1)\n",
        "        total += true_labels.data.ne(PAD).float().sum()\n",
        "        pred_correct = predict.eq(true_labels.data).masked_select(true_labels.ne(PAD).data).float().sum()\n",
        "        correct += pred_correct\n",
        "        batch+=1\n",
        "\n",
        "        labels_global.extend(true_labels.masked_select(true_labels.ne(PAD).data).cpu().data.numpy())\n",
        "        pred_global.extend(predict.masked_select(true_labels.ne(PAD).data).cpu().data.numpy())\n",
        "\n",
        "        # true_labels_list = list(true_labels.masked_select(true_labels.ne(PAD).data).cpu().data.numpy())\n",
        "        # predict = list(predict.masked_select(true_labels.ne(PAD).data).cpu().data.numpy())\n",
        "        # bsentences = [j for i in bsentences for j in i]\n",
        "        # for i in range(len(bsentences)):\n",
        "        #   print(bsentences[i] + \"\\t\" + LABEL_INDEX[true_labels_list[i]] + \"\\t\" + LABEL_INDEX[predict[i]])\n",
        "\n",
        "    test_acc = correct * 100.0 / total\n",
        "\n",
        "    f1 = f1_score(labels_global, pred_global, average='macro')\n",
        "\n",
        "    print(\"loss: {:.4f} eval acc: {:.4f} | f1 {:.4f}\".format(test_loss/batch, test_acc, f1))\n",
        "    return f1, test_loss/batch, test_acc\n",
        "\n",
        "def write_to_results(filename, trans_word_vocab_dict, es_translation_dict , char_vocab_dict, model):\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    labels_global = []\n",
        "    pred_global = []\n",
        "   \n",
        "    test_paths = ['Data/esp.train', 'Data/esp.testb']\n",
        "    sentences, OOV, labels = data_to_words_sentences(test_paths, es_translation_dict, test=True) #whole data\n",
        "\n",
        "    for data in batch_from_data(sentences, OOV, labels, 16, random=False):\n",
        "        # debug()\n",
        "        bsentences, bOOV, y = data\n",
        "        \n",
        "        transformer_word_input, word_input, word_length_input, char_input, char_length_input, label_input = get_input(trans_word_vocab_dict, word_to_index, bsentences, bOOV, char_vocab_dict, y, LABEL_INDEX)\n",
        "        loss, predict = model(transformer_word_input, word_input, char_input, word_length_input, char_length_input, label_input)\n",
        "        predict = predict.contiguous().view(-1)\n",
        "\n",
        "        true_labels = label_input.contiguous().view(-1)\n",
        "\n",
        "        labels_global.extend(list(true_labels.masked_select(true_labels.ne(PAD).data).cpu().data.numpy()))\n",
        "        pred_global.extend(list(predict.masked_select(true_labels.ne(PAD).data).cpu().data.numpy()))\n",
        "        # true_labels_list = list(true_labels.masked_select(true_labels.ne(PAD).data).cpu().data.numpy())\n",
        "        # predict = list(predict.masked_select(true_labels.ne(PAD).data).cpu().data.numpy())\n",
        "        # bsentences = [j for i in bsentences for j in i]\n",
        "        # for i in range(len(bsentences)):\n",
        "        #   print(bsentences[i] + \"\\t\" + LABEL_INDEX[true_labels_list[i]] + \"\\t\" + LABEL_INDEX[predict[i]])\n",
        "\n",
        "    sentence_tokens = [j for i in sentences for j in i]\n",
        "\n",
        "    with open(filename, \"w\") as f:\n",
        "        for i in range(len(sentence_tokens)):\n",
        "            f.write(sentence_tokens[i] + \"\\t\" + LABEL_INDEX[labels_global[i]] + \"\\t\" + LABEL_INDEX[pred_global[i]] + \"\\n\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IoY8DwYOb3Cf",
        "colab_type": "text"
      },
      "source": [
        "#Training and Evaluating"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gRB0YA1ub-pa",
        "colab_type": "text"
      },
      "source": [
        "##Loading data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hw6pjcq95im4",
        "colab_type": "code",
        "outputId": "3f34ef3f-2077-419a-e2c8-8d1e9e58cb75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd /content/gdrive/Shared drives/CIS 530 Project"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/Shared drives/CIS 530 Project\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8Oc394u5D6n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_paths = ['Data/eng.train', 'Data/eng.testa', 'Data/eng.testb']\n",
        "val_paths = ['Data/esp.testa']\n",
        "test_paths = ['Data/esp.train', 'Data/esp.testb']\n",
        "\n",
        "\n",
        "es_translation_dict = english_to_spanish_dict(\"translations_bi.txt\") \n",
        "all_paths=[]\n",
        "all_paths.extend(train_paths)\n",
        "all_paths.extend(val_paths)\n",
        "all_paths.extend(test_paths)  \n",
        "char_vocab_dict = create_char_index(all_paths, es_translation_dict, pad=False)\n",
        "matrix, word_to_index = get_indexed_word_embeddings(\"translations_bi.txt\", \"spanish.glove.gigaword_wiki.100d.magnitude\") #word_vector, word_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLPDlaYkb4g2",
        "colab_type": "text"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZqsWcyRUFT6U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "7c59154f-a3b9-499c-b587-1662c3f8a362"
      },
      "source": [
        "# change model name, generate results below\n",
        "global model_save_file \n",
        "model_save_file=\"Mbert_Extension_decay1e4\" \n",
        "global results_save_file\n",
        "results_save_file = \"results_Mbert_Extension_decay1e4.txt\"\n",
        "\n",
        "transformer_matrix, trans_word_vocab_dict = get_indexed_mbert_word_embeddings()\n",
        "transformer_hidden_size = transformer_matrix.shape[1]\n",
        "# transformer_matrix_tensor = torch.from_numpy(transformer_matrix)\n",
        "\n",
        "print(transformer_hidden_size)\n",
        "# model init call\n",
        "model = Attention_LSTM_CRF(transformer_hidden_size, transformer_matrix, len(char_vocab_dict), 25, len(matrix), 100, 200, matrix, len(LABEL_INDEX)).cuda()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.015, momentum=0.9, weight_decay=1e-4)\n",
        "# optimizer = torch.optim.Adam(model.parameters(), lr=0.0)\n",
        "\n",
        "\n",
        "all_train_loss, all_val_loss , all_train_acc, all_val_acc , all_train_f1 , all_val_f1 = training(model_save_file, trans_word_vocab_dict, es_translation_dict, char_vocab_dict, model, optimizer, 0.015, 30)\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "768\n",
            "from hinside 768\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:37: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:39: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:40: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0iA9mq4rcFi3",
        "colab_type": "text"
      },
      "source": [
        "##saving model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kaLzuUxG3h4d",
        "colab_type": "text"
      },
      "source": [
        "## Open model and write to results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JcB4w59H3deH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "9de8d9fb-6281-462c-930f-be8a73109166"
      },
      "source": [
        "\n",
        "model = Attention_LSTM_CRF(transformer_hidden_size, transformer_matrix, len(char_vocab_dict), 25, len(matrix), 100, 200, matrix, len(LABEL_INDEX)).cuda()\n",
        "model.load_state_dict(torch.load(model_save_file))\n",
        "\n",
        "write_to_results(results_save_file, trans_word_vocab_dict, es_translation_dict, char_vocab_dict, model)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "from hinside 768\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:37: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:39: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:40: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tf78BGnyvjKj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}