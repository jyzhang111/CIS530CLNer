{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of Copy of Copy4 of extension_integrated_v1.ipynb","provenance":[{"file_id":"1amNwL5iyfDAyHtZam4szX0GfVilXAB9T","timestamp":1588441994252},{"file_id":"1ouBrfEblFJTrTu_m4nRhHrOOz-r5EvHb","timestamp":1588310014165},{"file_id":"1uIQTfVfe79vfIaEKM5F3lNuYG7dlK1n5","timestamp":1588298013666},{"file_id":"1_U7aNsCBejUDtb-TN8ESs9TbL51123pg","timestamp":1588296230332}],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"254a88226ce04e489e228d1a2855a6af":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_9513ce0c5c2c4f37a4f208fd6cda496f","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_90c7d5e5da514ef0aa92da4e60c65da1","IPY_MODEL_9c861ddf8ac14cb49399da285d249e0a"]}},"9513ce0c5c2c4f37a4f208fd6cda496f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"90c7d5e5da514ef0aa92da4e60c65da1":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_01e051d550354dfeb68602bbfbf0c399","_dom_classes":[],"description":"Downloading: 100%","_model_name":"IntProgressModel","bar_style":"success","max":456,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":456,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_555ef8b054d84eb58b115d590c862cfa"}},"9c861ddf8ac14cb49399da285d249e0a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_a95dfd9025224ea88ad7fc20f86e3084","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 456/456 [00:01&lt;00:00, 378B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2fd35d134a0c40d79a6ada63b5e0dbcb"}},"01e051d550354dfeb68602bbfbf0c399":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"555ef8b054d84eb58b115d590c862cfa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a95dfd9025224ea88ad7fc20f86e3084":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"2fd35d134a0c40d79a6ada63b5e0dbcb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"cac4e698a6e24ad79b902bc7b760d68a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_d7702ef086f9426d9ad11ee2c8d3ae57","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_744e781c75524fd9bea37c21e1f11566","IPY_MODEL_5c92069db5444847b158cac6fd82bde6"]}},"d7702ef086f9426d9ad11ee2c8d3ae57":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"744e781c75524fd9bea37c21e1f11566":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_64a656b438334694ac4d5595c6175341","_dom_classes":[],"description":"Downloading: 100%","_model_name":"IntProgressModel","bar_style":"success","max":242120,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":242120,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d79397529cad4420aabb00762a9629b1"}},"5c92069db5444847b158cac6fd82bde6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_0fe7d602a1ed4696b72e06dafb945cdf","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 242k/242k [00:00&lt;00:00, 321kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_fa5669b79fd042539ee1a9426e198b83"}},"64a656b438334694ac4d5595c6175341":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"d79397529cad4420aabb00762a9629b1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0fe7d602a1ed4696b72e06dafb945cdf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"fa5669b79fd042539ee1a9426e198b83":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"26b8f1e044bc43798ff5ad01f038d691":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_4f45453fecb340a9966b7174065bbd49","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_6d330b60efff44f1a3d3aadbd4133472","IPY_MODEL_c6cc029ce2234b42a37eb395ac2df7f7"]}},"4f45453fecb340a9966b7174065bbd49":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6d330b60efff44f1a3d3aadbd4133472":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_4426d6013d7246e08f781f7bd1a8f8a0","_dom_classes":[],"description":"Downloading: 100%","_model_name":"IntProgressModel","bar_style":"success","max":2,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":2,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b4134dde87d0484a84155be50ec0ef48"}},"c6cc029ce2234b42a37eb395ac2df7f7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_75fa36bd4cda4552b9b1649af6bcded1","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 2.00/2.00 [00:00&lt;00:00, 4.17B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_006c2ec5e41d4baa90d38f1219c9fce0"}},"4426d6013d7246e08f781f7bd1a8f8a0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"b4134dde87d0484a84155be50ec0ef48":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"75fa36bd4cda4552b9b1649af6bcded1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"006c2ec5e41d4baa90d38f1219c9fce0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"55bf03c6db704788889b8ea7ec859ca9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_00a60ba83f71403f8adc051b7f30e048","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_558860a708f145bdbd204a1b1e796726","IPY_MODEL_512aa53a652c4de0bc2f38a348bc872f"]}},"00a60ba83f71403f8adc051b7f30e048":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"558860a708f145bdbd204a1b1e796726":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_82d9e3d91c854710a2575ea346fcb5f4","_dom_classes":[],"description":"Downloading: 100%","_model_name":"IntProgressModel","bar_style":"success","max":112,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":112,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f3a38c148ef54eaea3d3d8511ee3e111"}},"512aa53a652c4de0bc2f38a348bc872f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_78d9b7c30c394f6dba09728880901d22","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 112/112 [00:00&lt;00:00, 582B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_863dad3cc2844362944df2875e20c694"}},"82d9e3d91c854710a2575ea346fcb5f4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"f3a38c148ef54eaea3d3d8511ee3e111":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"78d9b7c30c394f6dba09728880901d22":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"863dad3cc2844362944df2875e20c694":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b499188560c944969c3d16af21838476":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_b7c55cd3ea104cdc875480a1cd12debd","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_8372c803be6a40a191681a346408330d","IPY_MODEL_7d7e90d311d5412f8ed5d9b548611341"]}},"b7c55cd3ea104cdc875480a1cd12debd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8372c803be6a40a191681a346408330d":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_fee15b00583a4baa84f33bdb570f03b9","_dom_classes":[],"description":"Downloading: 100%","_model_name":"IntProgressModel","bar_style":"success","max":43,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":43,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f9fec219ecc5487bb21164962cafbfee"}},"7d7e90d311d5412f8ed5d9b548611341":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_b5fd92756bbe41eca5229cbd6404fde6","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 43.0/43.0 [00:00&lt;00:00, 652B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_737f13821efc4cc1830211246422a5c3"}},"fee15b00583a4baa84f33bdb570f03b9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"f9fec219ecc5487bb21164962cafbfee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b5fd92756bbe41eca5229cbd6404fde6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"737f13821efc4cc1830211246422a5c3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5c503b802e894bdb83b4f6347cddda98":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_226e9d027b0d4e23aab5762fee82b811","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_d7753666b8e744d8ac8c32e34a291f46","IPY_MODEL_2761c62525dd4139b45458ffe0122af1"]}},"226e9d027b0d4e23aab5762fee82b811":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d7753666b8e744d8ac8c32e34a291f46":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_74134dd5adc64a4e9324d24da49b8b01","_dom_classes":[],"description":"Downloading: 100%","_model_name":"IntProgressModel","bar_style":"success","max":441944381,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":441944381,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e0349161ebd447a8a3505ba9d23df5d5"}},"2761c62525dd4139b45458ffe0122af1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_99f2ebd2583845749e2694ad222229da","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 442M/442M [00:08&lt;00:00, 52.0MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_63b014b6bdee44a4aa7e24e58b79ff9c"}},"74134dd5adc64a4e9324d24da49b8b01":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"e0349161ebd447a8a3505ba9d23df5d5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"99f2ebd2583845749e2694ad222229da":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"63b014b6bdee44a4aa7e24e58b79ff9c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"bJWDq-8og-mX","colab_type":"text"},"source":["# pytorch setup, imports and constants initialization"]},{"cell_type":"code","metadata":{"id":"bx60HT3t1LM-","colab_type":"code","colab":{}},"source":["# !pip uninstall tensorflow --yes\n","# !pip uninstall tensorboard --yes\n","# !pip install --ignore-installed tf-nightly"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fYAFESqjg8fM","colab_type":"code","outputId":"8cacc50f-ed12-450a-e41e-92ca17b2b5a0","executionInfo":{"status":"ok","timestamp":1588341083080,"user_tz":240,"elapsed":127721,"user":{"displayName":"John Zhang","photoUrl":"","userId":"12653864259381014680"}},"colab":{"base_uri":"https://localhost:8080/","height":255}},"source":["import os\n","from os.path import exists\n","from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n","platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n","cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n","accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n","!pip3 install https://download.pytorch.org/whl/cu100/torch-1.0.1-cp36-cp36m-linux_x86_64.whl\n","!pip3 install torch torchvision\n","  \n","import torch\n","device =  torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(device)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Collecting torch==1.0.1\n","\u001b[?25l  Downloading https://download.pytorch.org/whl/cu100/torch-1.0.1-cp36-cp36m-linux_x86_64.whl (614.8MB)\n","\u001b[K     |████████████████████████████████| 614.8MB 29kB/s \n","\u001b[31mERROR: torchvision 0.6.0+cu101 has requirement torch==1.5.0, but you'll have torch 1.0.1 which is incompatible.\u001b[0m\n","\u001b[?25hInstalling collected packages: torch\n","  Found existing installation: torch 1.5.0+cu101\n","    Uninstalling torch-1.5.0+cu101:\n","      Successfully uninstalled torch-1.5.0+cu101\n","Successfully installed torch-1.0.1\n","Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.0.1)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.6.0+cu101)\n","Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (7.0.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.18.3)\n","cuda:0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NK4-jWrThJd5","colab_type":"code","outputId":"74010896-8a86-4fe9-e6d0-445cb3a7e6d9","executionInfo":{"status":"ok","timestamp":1588341138490,"user_tz":240,"elapsed":173880,"user":{"displayName":"John Zhang","photoUrl":"","userId":"12653864259381014680"}},"colab":{"base_uri":"https://localhost:8080/","height":207}},"source":["!pip3 install pymagnitude\n","from pymagnitude import *\n","\n","import time\n","import argparse\n","import numpy as np\n","import time\n","import torch\n","import torch.nn as nn\n","from torch.autograd import Variable\n","from torch import optim\n","from torch.nn.utils.rnn import pad_packed_sequence, pack_padded_sequence\n","from sklearn.metrics import f1_score\n","from pdb import set_trace as debug\n","import pickle\n","\n","# Flag, set to True if you want to use DE data as well for pretraining\n","use_de = True\n","\n","PAD = 0\n","UNK = 1\n","BOS = 2\n","EOS = 3\n","\n","PAD_WORD = '<blank>'\n","UNK_WORD = '<unk>'\n","BOS_WORD = '<s>'\n","EOS_WORD = '</s>'\n","\n","CAT = ['PER', 'ORG', 'LOC', 'MISC']\n","POSITION = ['I', 'B']\n","LABEL_INDEX = [PAD_WORD] + ['O'] + [\"{}-{}\".format(position, cat) for cat in CAT for position in POSITION]\n","\n","train_paths = ['Data/eng.train', 'Data/eng.testa', 'Data/eng.testb']\n","if use_de: train_paths.extend(['Data/ned.train', 'Data/ned.testa', 'Data/ned.testb'])\n","val_paths = ['Data/esp.testa']\n","test_paths = ['Data/esp.train', 'Data/esp.testb']"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Collecting pymagnitude\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0a/a3/b9a34d22ed8c0ed59b00ff55092129641cdfa09d82f9abdc5088051a5b0c/pymagnitude-0.1.120.tar.gz (5.4MB)\n","\u001b[K     |████████████████████████████████| 5.4MB 2.7MB/s \n","\u001b[?25hBuilding wheels for collected packages: pymagnitude\n","  Building wheel for pymagnitude (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pymagnitude: filename=pymagnitude-0.1.120-cp36-cp36m-linux_x86_64.whl size=135918206 sha256=11f6df26f0ee805a065eaf5d7b1d5fb1b8c37ea5bd8de026db2cd842bc63c93f\n","  Stored in directory: /root/.cache/pip/wheels/a2/c7/98/cb48b9db35f8d1a7827b764dc36c5515179dc116448a47c8a1\n","Successfully built pymagnitude\n","Installing collected packages: pymagnitude\n","Successfully installed pymagnitude-0.1.120\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"vvgAcjm6hyiH","colab_type":"text"},"source":["# Connect to Google Drive"]},{"cell_type":"code","metadata":{"id":"0YfhNBjSynDh","colab_type":"code","outputId":"d1c73388-5530-4065-e07b-8a5f52b2648c","executionInfo":{"status":"ok","timestamp":1588340961420,"user_tz":240,"elapsed":22777,"user":{"displayName":"John Zhang","photoUrl":"","userId":"12653864259381014680"}},"colab":{"base_uri":"https://localhost:8080/","height":139}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n","\n","%cd \"/content/gdrive/Shared drives/CIS 530 Project/\""],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n","/content/gdrive/Shared drives/CIS 530 Project\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"sy2KI9Gxtiio","colab_type":"text"},"source":["# Embeddings from Transformer models"]},{"cell_type":"markdown","metadata":{"id":"-JpVDSyaGSj8","colab_type":"text"},"source":["##BERT"]},{"cell_type":"code","metadata":{"id":"HYITTxC4gT3t","colab_type":"code","outputId":"cb2846b3-5c73-4968-832e-1ebfade60102","executionInfo":{"status":"ok","timestamp":1588341140357,"user_tz":240,"elapsed":171850,"user":{"displayName":"John Zhang","photoUrl":"","userId":"12653864259381014680"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["def load_obj(name ):\n","  with open('obj/' + name + '.pkl', 'rb') as f:\n","    return pickle.load(f)\n","\n","# Returns a tuple (numpy matrix, word_to_index dict) where the matrix contains all the \n","# X-dimensional word embeddings, and word_to_index is a dictionary from the\n","# word into the index in the matrix. For Out-of-vocabulary words it uses\n","# a [UNK] or <unused> embedding\n","def get_indexed_mbert_word_embeddings():\n","  loaded_list = load_obj('mbert_matrix_v3')\n","  loaded_np_matrix = np.asarray(loaded_list)\n","  loaded_word_to_idx = load_obj('mbert_word_to_index_v3')\n","  return loaded_np_matrix, loaded_word_to_idx \n","\n","mat, idx = get_indexed_mbert_word_embeddings()\n","# embed = mat[idx.get('cat')]\n","print(len(idx))\n","# print(type(embed))\n","# print(embed.shape)\n","print(mat.shape)\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["56007\n","(56007, 768)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"FGACLiBXofNq","colab_type":"text"},"source":["## BETO"]},{"cell_type":"code","metadata":{"id":"cSayKr9gogk4","colab_type":"code","outputId":"382c04d5-237c-452f-9fe8-14303611a5e8","executionInfo":{"status":"ok","timestamp":1588341165507,"user_tz":240,"elapsed":194998,"user":{"displayName":"John Zhang","photoUrl":"","userId":"12653864259381014680"}},"colab":{"base_uri":"https://localhost:8080/","height":977,"referenced_widgets":["254a88226ce04e489e228d1a2855a6af","9513ce0c5c2c4f37a4f208fd6cda496f","90c7d5e5da514ef0aa92da4e60c65da1","9c861ddf8ac14cb49399da285d249e0a","01e051d550354dfeb68602bbfbf0c399","555ef8b054d84eb58b115d590c862cfa","a95dfd9025224ea88ad7fc20f86e3084","2fd35d134a0c40d79a6ada63b5e0dbcb","cac4e698a6e24ad79b902bc7b760d68a","d7702ef086f9426d9ad11ee2c8d3ae57","744e781c75524fd9bea37c21e1f11566","5c92069db5444847b158cac6fd82bde6","64a656b438334694ac4d5595c6175341","d79397529cad4420aabb00762a9629b1","0fe7d602a1ed4696b72e06dafb945cdf","fa5669b79fd042539ee1a9426e198b83","26b8f1e044bc43798ff5ad01f038d691","4f45453fecb340a9966b7174065bbd49","6d330b60efff44f1a3d3aadbd4133472","c6cc029ce2234b42a37eb395ac2df7f7","4426d6013d7246e08f781f7bd1a8f8a0","b4134dde87d0484a84155be50ec0ef48","75fa36bd4cda4552b9b1649af6bcded1","006c2ec5e41d4baa90d38f1219c9fce0","55bf03c6db704788889b8ea7ec859ca9","00a60ba83f71403f8adc051b7f30e048","558860a708f145bdbd204a1b1e796726","512aa53a652c4de0bc2f38a348bc872f","82d9e3d91c854710a2575ea346fcb5f4","f3a38c148ef54eaea3d3d8511ee3e111","78d9b7c30c394f6dba09728880901d22","863dad3cc2844362944df2875e20c694","b499188560c944969c3d16af21838476","b7c55cd3ea104cdc875480a1cd12debd","8372c803be6a40a191681a346408330d","7d7e90d311d5412f8ed5d9b548611341","fee15b00583a4baa84f33bdb570f03b9","f9fec219ecc5487bb21164962cafbfee","b5fd92756bbe41eca5229cbd6404fde6","737f13821efc4cc1830211246422a5c3","5c503b802e894bdb83b4f6347cddda98","226e9d027b0d4e23aab5762fee82b811","d7753666b8e744d8ac8c32e34a291f46","2761c62525dd4139b45458ffe0122af1","74134dd5adc64a4e9324d24da49b8b01","e0349161ebd447a8a3505ba9d23df5d5","99f2ebd2583845749e2694ad222229da","63b014b6bdee44a4aa7e24e58b79ff9c"]}},"source":["!pip3 install transformers\n","# !wget https://users.dcc.uchile.cl/~jperez/beto/cased_2M/pytorch_weights.tar.gz \n","# !wget https://users.dcc.uchile.cl/~jperez/beto/cased_2M/vocab.txt \n","# !wget https://users.dcc.uchile.cl/~jperez/beto/cased_2M/config.json \n","# !tar -xzvf pytorch_weights.tar.gz\n","# !mv config.json pytorch/.\n","# !mv vocab.txt pytorch/.\n","\n","from transformers import AutoTokenizer, AutoModelWithLMHead\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"dccuchile/bert-base-spanish-wwm-cased\")\n","model_beto = AutoModelWithLMHead.from_pretrained(\"dccuchile/bert-base-spanish-wwm-cased\")\n","model_beto.eval()\n","model_beto.cuda()\n","\n","# Returns a tuple (numpy matrix, word_to_index dict) where the matrix contains all the \n","# X-dimensional word embeddings, and word_to_index is a dictionary from the\n","# word into the index in the matrix. For Out-of-vocabulary words it uses\n","# a [UNK] or <unused> embedding\n","def get_indexed_beto_word_embeddings():\n","  path = \"pytorch/vocab.txt\"\n","  idx=0\n","  word_to_index = dict()\n","  with open(path, 'r') as f:\n","    for line in f:\n","        line = line.rstrip('\\n').split('\\t')\n","        word_to_index[line[0]] = idx\n","        idx=idx+1 \n","\n","  matrix = model_beto.get_input_embeddings().weight.data\n","  np_matrix = matrix.cpu().numpy()\n","\n","  return np.asarray(np_matrix), word_to_index\n","\n","# mat, word_to_idx = get_indexed_beto_word_embeddings()\n","# print(mat.shape)\n","# embed = mat[word_to_idx.get('para'),3] #default value if word not found is <UNK> or index 3.\n","# print(embed.shape)\n","# print(type(embed))\n","# print(embed)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/78/92cedda05552398352ed9784908b834ee32a0bd071a9b32de287327370b7/transformers-2.8.0-py3-none-any.whl (563kB)\n","\u001b[K     |████████████████████████████████| 573kB 2.6MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.38.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Collecting tokenizers==0.5.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n","\u001b[K     |████████████████████████████████| 3.7MB 5.9MB/s \n","\u001b[?25hCollecting sentencepiece\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/2c/8df20f3ac6c22ac224fff307ebc102818206c53fc454ecd37d8ac2060df5/sentencepiece-0.1.86-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n","\u001b[K     |████████████████████████████████| 1.0MB 29.7MB/s \n","\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/50/93509f906a40bffd7d175f97fd75ea328ad9bd91f48f59c4bd084c94a25e/sacremoses-0.0.41.tar.gz (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 41.4MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.12.47)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.14.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.1)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.9)\n","Requirement already satisfied: botocore<1.16.0,>=1.15.47 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.15.47)\n","Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.5)\n","Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n","Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.47->boto3->transformers) (0.15.2)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.47->boto3->transformers) (2.8.1)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.41-cp36-none-any.whl size=893334 sha256=aabc19fe30dad21e622dde7214d6435802365c3ca8445653678a72ba654592b4\n","  Stored in directory: /root/.cache/pip/wheels/22/5a/d4/b020a81249de7dc63758a34222feaa668dbe8ebfe9170cc9b1\n","Successfully built sacremoses\n","Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n","Successfully installed sacremoses-0.0.41 sentencepiece-0.1.86 tokenizers-0.5.2 transformers-2.8.0\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"254a88226ce04e489e228d1a2855a6af","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=0, description='Downloading', max=456, style=ProgressStyle(description_width=…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cac4e698a6e24ad79b902bc7b760d68a","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=0, description='Downloading', max=242120, style=ProgressStyle(description_wid…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"26b8f1e044bc43798ff5ad01f038d691","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=0, description='Downloading', max=2, style=ProgressStyle(description_width='i…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"55bf03c6db704788889b8ea7ec859ca9","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=0, description='Downloading', max=112, style=ProgressStyle(description_width=…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b499188560c944969c3d16af21838476","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=0, description='Downloading', max=43, style=ProgressStyle(description_width='…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5c503b802e894bdb83b4f6347cddda98","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=0, description='Downloading', max=441944381, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"vZxser1ahU72","colab_type":"text"},"source":["# Utility Functions"]},{"cell_type":"code","metadata":{"id":"hhafrdBfhXZo","colab_type":"code","colab":{}},"source":["# Returns the dictionary from the file with translations\n","def language_to_spanish_dict(path):\n","  l_to_spanish = dict()\n","\n","  with open(path, 'r') as f:\n","    for line in f:\n","        line = line.rstrip('\\n').split('\\t')\n","        en_word = line[0]\n","        es_word = line[1]\n","        if en_word.isupper(): l_to_spanish[en_word] = es_word.upper()\n","        elif len(en_word) > 0 and en_word[0].isupper(): l_to_spanish[en_word] = es_word.capitalize()\n","        else: l_to_spanish[en_word] = es_word\n","\n","  return l_to_spanish\n","\n","# Returns a matrix of category distributions of the translation word, seen in\n","# the training set, or for all test words the closes translation word\n","def previous_ner_distributions(embedding_matrix, word_to_index, en_to_spanish, de_to_spanish=None):\n","  embedding_size = embedding_matrix.shape[1]\n","  translation_words = []\n","  translation_words_matrix = []\n","  category_distribution_matrix = np.zeros((len(word_to_index), 5))\n","\n","  # Columns = O, PER, ORG, LOC, MISC\n","  en_files = [f for f in train_paths if 'eng' in f]\n","  for file in en_files:\n","    with open(file, 'r') as f:\n","      for line in f:\n","        line = line.rstrip('\\n')\n","        if line == \"\": continue\n","\n","        word = line.split()[0]\n","        trans = en_to_spanish[word]\n","        tag = line.split()[3]\n","        if trans not in translation_words:\n","          translation_words.append(trans)\n","          translation_words_matrix.append(embedding_matrix[word_to_index[trans], :])\n","        col = 0\n","        if 'PER' in tag: col = 1\n","        elif 'ORG' in tag: col = 2\n","        elif 'LOC' in tag: col = 3\n","        elif 'MISC' in tag: col = 4\n","        category_distribution_matrix[word_to_index[trans], col] += 1\n","\n","  if de_to_spanish:\n","    de_files = [f for f in train_paths if 'ned' in f]\n","    for file in de_files:\n","      with open(file, 'r') as f:\n","        for line in f:\n","          line = line.rstrip('\\n')\n","          if line == \"\": continue\n","\n","          word = line.split()[0]\n","          trans = de_to_spanish[word]\n","          tag = line.split()[2]\n","          if trans not in translation_words:\n","            translation_words.append(trans)\n","            translation_words_matrix.append(embedding_matrix[word_to_index[trans], :])\n","          col = 0\n","          if 'PER' in tag: col = 1\n","          elif 'ORG' in tag: col = 2\n","          elif 'LOC' in tag: col = 3\n","          elif 'MISC' in tag: col = 4\n","          category_distribution_matrix[word_to_index[trans], col] += 1\n","\n","  translation_words_matrix = np.array(translation_words_matrix)\n","  norms = np.linalg.norm(translation_words_matrix, axis=1)\n","  # ratios on each row\n","  sums = np.maximum(category_distribution_matrix.sum(axis=1), 1)\n","  category_distribution_matrix = category_distribution_matrix / sums[:, None]\n","\n","  es_files = val_paths + test_paths\n","\n","  for file in es_files:\n","    with open(file, 'r') as f:\n","      for line in f:\n","        line = line.rstrip('\\n')\n","        if line == \"\": continue\n","\n","        word = line.split()[0]\n","        if category_distribution_matrix[word_to_index[word], :].sum() == 0:\n","          embedding = embedding_matrix[word_to_index[word], :]\n","          embedding = np.reshape(embedding, (embedding_size, 1))\n","          closeness = np.matmul(translation_words_matrix, embedding)/norms[:, None]\n","          closest_distribution = category_distribution_matrix[word_to_index[translation_words[np.argmax(closeness)]], :]\n","          category_distribution_matrix[word_to_index[word], :] = closest_distribution\n","\n","  return category_distribution_matrix\n","\n","def get_category_average_word_embeddings(matrix, en_to_spanish, word_to_index, de_to_spanish=None):\n","  CAT_TO_IDX = {'PER':0, 'ORG':1, 'LOC':2, 'MISC':3, 'O':4}\n","  CAT = ['PER', 'ORG', 'LOC', 'MISC', 'O']\n","  dim = matrix.shape[1]\n","\n","  CAT_EMB = np.array([[0 for i in range(dim)] for j in range(len(CAT))], dtype=np.float64)\n","  \n","  cnt = [0]*5\n","  en_files = [f for f in train_paths if 'eng' in f]\n","  for file in en_files:\n","    with open(file, 'r') as f:\n","      for line in f:\n","        line = line.rstrip('\\n')\n","        if line == \"\": continue\n","\n","        word = line.split()[0]\n","        cat = line.split()[3].replace('I-','').replace('B-','')\n","        trans = en_to_spanish[word]\n","\n","        emb = np.squeeze(matrix[word_to_index[trans], :])\n","\n","        CAT_EMB[CAT_TO_IDX[cat]] += emb\n","        cnt[CAT_TO_IDX[cat]]+=1\n","\n","  if de_to_spanish:\n","    de_files = [f for f in train_paths if 'ned' in f]\n","    for file in de_files:\n","      with open(file, 'r') as f:\n","        for line in f:\n","          line = line.rstrip('\\n')\n","          if line == \"\": continue\n","\n","          word = line.split()[0]\n","          cat = line.split()[2].replace('I-','').replace('B-','')\n","          trans = de_to_spanish[word]\n","\n","          emb = np.squeeze(matrix[word_to_index[trans], :])\n","\n","          CAT_EMB[CAT_TO_IDX[cat]] += emb\n","          cnt[CAT_TO_IDX[cat]]+=1\n","\n","  cnt = np.array(cnt)\n","  cnt = cnt[:,np.newaxis]\n","  CAT_EMB = np.divide(CAT_EMB,cnt)\n","  return CAT_EMB\n","\n","def find_distance(dim, cat_emb, emb):\n","  dis = []\n","  for i in range(len(cat_emb)):\n","    dis.append(np.inner(cat_emb[i], emb) / (np.linalg.norm(cat_emb[i]) * np.linalg.norm(emb)))\n","\n","  return dis\n","\n","def all_distances(matrix, word_to_index, en_to_spanish, de_to_spanish=None):\n","  dim = matrix.shape[1]\n","  all_category_distances = []\n","\n","  cat_emb = get_category_average_word_embeddings(matrix, en_to_spanish, word_to_index, de_to_spanish)\n","  for i in range(matrix.shape[0]):\n","    all_category_distances.append(find_distance(dim, cat_emb, matrix[i, :]))\n","  return np.array(all_category_distances)\n","\n","def get_distributional_info(embedding_matrix, word_to_index, en_to_spanish, distance=True, de_to_spanish=None):\n","  if distance: return all_distances(embedding_matrix, word_to_index, en_to_spanish, de_to_spanish)\n","  else: return previous_ner_distributions(embedding_matrix, word_to_index, en_to_spanish, de_to_spanish)\n","\n","# Returns a tuple (matrix, word_to_index) where the matrix contains all the \n","# X-dimensional word embeddings, and word_to_index is a dictionary from the\n","# word into the index in the matrix. For Out-of-vocabulary words it creates\n","# a random embedding\n","def get_indexed_word_embeddings(en_to_spanish, embedding_path, de_to_spanish=None):\n","  vectors = Magnitude(embedding_path)\n","\n","  dim = vectors.dim\n","  \n","  matrix = [] # words by embedding-dimension\n","  word_to_index = dict()\n","\n","  index = 0\n","\n","  en_files = [f for f in train_paths if 'eng' in f]\n","  \n","  for file in en_files:\n","    with open(file, 'r') as f:\n","      for line in f:\n","        line = line.rstrip('\\n')\n","        if line == \"\": continue\n","\n","        word = line.split()[0]\n","        trans = en_to_spanish[word]\n","        if trans not in word_to_index:\n","          word_to_index[trans] = index\n","          if trans in vectors: matrix.append(vectors.query(trans))\n","          else: matrix.append(np.random.uniform(-(3/dim)**0.5, (3/dim)**0.5, dim))\n","\n","          index += 1\n","\n","  if de_to_spanish:\n","    de_files = [f for f in train_paths if 'ned' in f]\n","    for file in de_files:\n","      with open(file, 'r') as f:\n","        for line in f:\n","          line = line.rstrip('\\n')\n","          if line == \"\": continue\n","\n","          word = line.split()[0]\n","          trans = de_to_spanish[word]\n","          if trans not in word_to_index:\n","            word_to_index[trans] = index\n","            if trans in vectors: matrix.append(vectors.query(trans))\n","            else: matrix.append(np.random.uniform(-(3/dim)**0.5, (3/dim)**0.5, dim))\n","\n","            index += 1\n","\n","  es_files = val_paths + test_paths\n","  \n","  for file in es_files:\n","    with open(file, 'r') as f:\n","      for line in f:\n","        line = line.rstrip('\\n')\n","        if line == \"\": continue\n","\n","        word = line.split()[0]\n","        if word not in word_to_index:\n","          word_to_index[word] = index\n","          if word in vectors: matrix.append(vectors.query(word))\n","          else: matrix.append(np.random.uniform(-(3/dim)**0.5, (3/dim)**0.5, dim))\n","            \n","          index += 1\n","\n","  return np.array(matrix), word_to_index\n","\n","#returns char dictionary created from all path in paths\n","def create_char_index(paths, en_to_spanish, pad=False, de_to_spanish=None):\n","    char_dict = {}\n","    if pad:\n","        char_dict[PAD_WORD] = PAD\n","        char_dict[UNK_WORD] = UNK\n","    else:\n","        char_dict[UNK_WORD] = 0\n","\n","    for path in paths:\n","        for line in open(path):\n","            l = line.strip().split()\n","            if len(l) > 0:# and l[0] != '':\n","              #l[0] is word l[1] is POS, l[2] is gold standard NER label\n","              word = l[0]\n","              es_word = word\n","              if 'eng' in path and word in en_to_spanish:\n","                es_word = en_to_spanish.get(word)\n","              if de_to_spanish:\n","                if 'ned' in path and word in de_to_spanish:\n","                  es_word = de_to_spanish.get(word)\n","              for i in range(len(es_word)):\n","                  if es_word[i] not in char_dict:\n","                      char_dict[es_word[i]] = len(char_dict)\n","\n","    return char_dict\n","\n","#   Returns \n","#1. all the spanish 'sentences' in 2D array\n","#2. 2D array indicating if word in given sentence is OOV word (True if the word is used as-is, translation not found) or not\n","#3. 2D array returning labels.\n","#   in the file(s) at paths in an array.\n","def data_to_words_sentences(paths, en_to_spanish, test=False, de_to_spanish=None):\n","  sentences=[]\n","  curr_sentence=[]\n","  OOV = []\n","  labels=[]\n","  curr_OOV_sentence = []\n","  curr_label_sentence = []\n","  word_idx = 0\n","  for path in paths:\n","      for line in open(path):\n","        line = line.strip().split()\n","        \n","        end_of_line=False\n","        if len(line) == 0:\n","          end_of_line=True\n","        \n","        if not end_of_line:\n","          word = line[0]\n","          es_word = word\n","\n","          if not test:\n","            if 'eng' in path: curr_label_sentence.append(line[3]) #english has 4th column label\n","            else: curr_label_sentence.append(line[2]) #dutch has 3rd column label\n","          else: #spanish has 3rd column label\n","            curr_label_sentence.append(line[2])\n","\n","          curr_OOV_sentence.append(True)\n","          if test:\n","            curr_OOV_sentence[word_idx] = False\n","          else: #not test\n","            if 'eng' in path and word in en_to_spanish:\n","              es_word = en_to_spanish.get(word)\n","              curr_OOV_sentence[word_idx] = False\n","            elif de_to_spanish:\n","              if word in de_to_spanish:\n","                es_word = de_to_spanish.get(word)\n","                curr_OOV_sentence[word_idx] = False\n","          \n","          word_idx = word_idx+1\n","          curr_sentence.append(es_word)\n","        if end_of_line:\n","          sentences.append(curr_sentence)\n","          OOV.append(curr_OOV_sentence)\n","          labels.append(curr_label_sentence)\n","          curr_sentence=[]\n","          curr_OOV_sentence=[]\n","          curr_label_sentence=[]\n","          word_idx=0\n","  return sentences, OOV, labels"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TeSYLEOZx4jr","colab_type":"text"},"source":["##Get_input fucntion"]},{"cell_type":"code","metadata":{"id":"BmzyybTXx3B8","colab_type":"code","colab":{}},"source":["#ADD all methods to get initial input to neural network here. Returns char, labels and word input\n","#OOV[i] indicates if word[i] is OOV (translation not found)\n","def get_input(transformer_word_vocab_dict, word_vocab_dict, sentences, OOV, char_vocab_dict, token_labels, label_to_index):\n","  max_word_len = max(len(word) for sentence in sentences for word in sentence)\n","  #max_word_len = max(len(word) for word in words)\n","  max_sentence_length = max(len(sentence) for sentence in sentences)\n","\n","  word_input = np.zeros((len(sentences), max_sentence_length), dtype='int64')\n","  word_input_length = [len(sentence) for sentence in sentences]\n","\n","  char_input = np.zeros((len(sentences), max_sentence_length,max_word_len), dtype='int64') \n","  char_input_length = np.zeros((len(sentences), max_sentence_length), dtype='int64') #2D array of length of word in each sentence in sentences\n","  \n","  # word_mbert_input = get_mbert_es_embeddings(sentences, max_sentence_length)\n","  transformer_word_input = np.zeros((len(sentences), max_sentence_length), dtype='int64')\n","\n","\n","  label_input = np.zeros((len(sentences), max_sentence_length), dtype='int64') #2D array of label of word in each sentence in sentences\n","  for i in range(len(sentences)):\n","    for j in range(len(sentences[i])):\n","      word_input[i][j] = word_vocab_dict[sentences[i][j]]\n","\n","      # if transformer_word_vocab_dict.get(sentences[i][j]) is not None:\n","      transformer_word_input[i][j] = transformer_word_vocab_dict[sentences[i][j]]\n","      #transformer_word_input[i][j] = transformer_word_vocab_dict.get(sentences[i][j],3)\n","        # print(sentences[i][j])\n","        # print(transformer_word_vocab_dict[sentences[i][j]])\n","      # else:\n","      #   # print(sentences[i][j])\n","      #   print(\"word not found\")\n","      #   transformer_word_input[i][j] = len(transformer_word_vocab_dict) #handling OOV, assign last index\n","\n","      char_input_length[i][j] = len(sentences[i][j]) \n","      label_input[i][j] = label_to_index.index(token_labels[i][j])\n","\n","      for k in range(len(sentences[i][j])):\n","        c = sentences[i][j][k]\n","        if c in char_vocab_dict:\n","          input_zero = c.isdigit() or OOV[i][j]\n","          char_input[i][j][k] = char_vocab_dict['0' if input_zero else c]\n","        else:\n","          char_input[i][j][k] = UNK\n","\n","  word_input_var = Variable(torch.from_numpy(word_input), requires_grad=False)\n","  transformer_word_input_var = Variable(torch.from_numpy(transformer_word_input), requires_grad=False)\n","  word_input_length_var = Variable(torch.LongTensor(word_input_length), requires_grad=False)\n","  label_var = Variable(torch.from_numpy(label_input), requires_grad=False)\n","  char_input_var = Variable(torch.from_numpy(char_input), requires_grad=False)\n","  char_input_length_var = Variable(torch.from_numpy(char_input_length), requires_grad=False)\n","  return transformer_word_input_var.cuda(), word_input_var.cuda(), word_input_length_var.cuda(), char_input_var.cuda(), char_input_length_var.cuda(), label_var.cuda()\n","\n","def batch_from_data(X, X1, y, batch_size, random=True):\n","    batch_num = int(np.ceil(len(y) / float(batch_size)))\n","    rand_indices = np.arange(len(y))\n","    if random: rand_indices = np.random.permutation(len(y))\n","\n","    for batch in range(0, batch_num):\n","        bs = batch_size if batch < batch_num - 1 else len(y) - batch_size * batch\n","        #from pdb import set_trace as debug\n","        #debug()\n","        yield [X[i] for i in rand_indices[batch * batch_size : batch * batch_size + bs]], [X1[i] for i in rand_indices[batch * batch_size : batch * batch_size + bs]], [y[i] for i in rand_indices[batch * batch_size : batch * batch_size + bs]]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wpY4fK3phkHJ","colab_type":"text"},"source":["# Model"]},{"cell_type":"markdown","metadata":{"id":"gzIbKaR0bph_","colab_type":"text"},"source":["##char embedding"]},{"cell_type":"code","metadata":{"id":"FPyhlkQQhmfg","colab_type":"code","colab":{}},"source":["class char_model(nn.Module):\n","    def __init__(self, char_vocab_size, char_embed_size, char_lstm_hidden_size=50):\n","\n","        #START: char embedding section\n","        super(char_model, self).__init__()\n","        self.char_embed = nn.Embedding(char_vocab_size, char_embed_size, padding_idx=PAD)\n","        self.char_lstm = nn.LSTM(char_embed_size, char_lstm_hidden_size, bidirectional=True, batch_first=True)\n","        self.char_lstm_hidden_size = char_lstm_hidden_size\n","        #END: char embedding section \n","\n","    def forward(self, char_inp, char_input_length):\n","\n","        #START: char embedding section\n","        #from pdb import set_trace as debug\n","        #debug()\n","        char_input = char_inp.view(-1, char_inp.size(2))\n","        char_input_length_sorted, char_original_idx = char_input_length.view(-1).sort(0, descending=True)\n","        char_embedded = self.char_embed(char_input)\n","        char_embedded_sorted = char_embedded[char_original_idx] #get embeddings in descending order of length of word in words\n","\n","        char_input_length_sorted_size = char_input_length_sorted.size(0)\n","        last_index = char_input_length_sorted_size\n","        if char_input_length_sorted.data.eq(0).sum() != 0: #atleast 1 element of char_input_length_sorted is/are zero\n","          last_index = char_input_length_sorted.data.eq(0).nonzero()[0][0]\n","        char_embedded_sorted = char_embedded_sorted[:last_index]\n","        char_input_length_sorted = char_input_length_sorted[:last_index]\n","\n","        char_input_packed_padded = pack_padded_sequence(char_embedded_sorted, char_input_length_sorted.cpu().data.numpy(), batch_first=True)\n","        char_output_packed_padded, (h_n, c_n) = self.char_lstm(char_input_packed_padded)\n","        char_hidden_state = torch.cat([h_n[0], h_n[1]], 1)\n","\n","        if last_index != char_input_length_sorted_size:\n","          zero_padding_diff = char_input_length_sorted_size - last_index\n","          zero_padding = Variable(torch.zeros((zero_padding_diff, 2*self.char_lstm_hidden_size)), requires_grad=False).cuda()\n","          char_hidden_state = torch.cat([char_hidden_state, zero_padding], 0)\n","\n","        char_hidden_state = char_hidden_state[torch.argsort(char_original_idx)] #char_hidden_state[torch.from_numpy(np.argsort(char_original_idx.cpu().data.numpy())).cuda()]\n","        char_hidden_state = char_hidden_state.view(char_inp.size(0), -1, char_hidden_state.size(1))\n","        return char_hidden_state\n","        #END: char embedding section \n","\n","    def reset_parameters(self):\n","\n","      #START: char embedding section\n","      for param in self.char_embed.parameters():\n","          nn.init.normal(param, mean=0, std=0.01)\n","\n","      for name, param in self.char_lstm.named_parameters():\n","          if 'bias' in name:\n","              nn.init.constant_(param, 0.)\n","          elif 'weight' in name:\n","              nn.init.normal(param, mean=0, std=0.1)\n","      #END: char embedding section "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DY26JE0ebtmV","colab_type":"text"},"source":["##Self Attention"]},{"cell_type":"code","metadata":{"id":"evmwaqT6-fal","colab_type":"code","colab":{}},"source":["class selfAttention(nn.Module):\n","\n","  def __init__(self, transformer_hidden_size, transformer_matrix, char_lstm_hidden_size, word_vocab_size, word_embedding_size, word_lstm_hiddden_size, word_vector):\n","    super(selfAttention, self).__init__()\n","    self.word_embed = nn.Embedding(word_vocab_size, word_embedding_size, padding_idx=PAD)\n","    self.transformer_matrix = transformer_matrix\n","    self.transformer_hidden_size = transformer_hidden_size\n","\n","    self.word_lstm = nn.LSTM(2*char_lstm_hidden_size + word_embedding_size + transformer_hidden_size, word_lstm_hiddden_size, batch_first=True, bidirectional=True)\n","    self.word_linear = nn.Linear(word_lstm_hiddden_size * 2, word_lstm_hiddden_size * 2)\n","\n","    self.tanh = nn.Tanh()\n","    self.softmax = nn.Softmax(dim=2)\n","    self.embedding_dropout = nn.Dropout(0.5)\n","    self.word_dropout = nn.Dropout(0.5)\n","    self.att_sm_dropout = nn.Dropout(0.5)\n","    #self.att_dropout= nn.Dropout(0.2)\n","    self.word_embed.weight.data.copy_(torch.from_numpy(np.asarray(word_vector)))\n","\n","\n","  def forward(self, transformer_word_input, words, char_hidden_state, word_length):\n","    # word_embedding = self.word_embed(words).cuda()\n","    word_embedding = self.word_embed(words)\n","\n","    transformer_word_embed = (self.TransformerEmbedder(transformer_word_input)).float().cuda()\n","    # debug()\n","    ## Note: nn.embed is returning CPU tensors and not CUDA tensors, also char_hidden_state is also not on CUDA \n","    # word_lstm_input = torch.cat([transformer_word_embed, word_embedding, char_hidden_state.cuda()], 2) #here\n","    word_lstm_input = torch.cat([transformer_word_embed, word_embedding, char_hidden_state], 2) #here\n","\n","    word_lstm_input = self.embedding_dropout(word_lstm_input)\n","    \n","    word_length, word_idx = word_length.sort(0, descending=True)\n","    word_lstm_input = word_lstm_input[word_idx]\n","\n","    word_packed_input = pack_padded_sequence(word_lstm_input, word_length.cpu().data.numpy(), batch_first=True)\n","    word_packed_output, _ = self.word_lstm(word_packed_input)\n","    word_output, _ = pad_packed_sequence(word_packed_output, batch_first=True)\n","    word_output = word_output[torch.from_numpy(np.argsort(word_idx.cpu().data.numpy())).cuda()]\n","    \n","    word_output = self.word_dropout(word_output)\n","    attn_input = self.tanh(self.word_linear(word_output))\n","\n","    att_padding_mask = Variable(words.data.ne(PAD)).cuda()\n","    context = attn_input * att_padding_mask.float().unsqueeze(2)\n","    attn_out = context.bmm(context.transpose(1, 2))\n","\n","    attention_self_mask = Variable(1 - torch.eye(words.size(1), words.size(1))).cuda()\n","    attn_out = attn_out * attention_self_mask.unsqueeze(0)\n","\n","    out = self.softmax(attn_out)\n","    out = out * att_padding_mask.float().unsqueeze(2)\n","    out = out * att_padding_mask.float().unsqueeze(1)\n","    out = self.att_sm_dropout(out)\n","    context_v = out.bmm(word_output)\n","    #context_v = self.att_dropout(context_v)\n","    word_output = torch.cat([word_output, context_v], 2)\n","\n","    return word_output\n","\n","\n","  def TransformerEmbedder(self, transformer_word_input):\n","    b, s = transformer_word_input.shape # batch, sentence\n","    h = self.transformer_hidden_size # hidden\n","    batch_embed = np.zeros((b, s, h))\n","    # debug()\n","    for i, sentence_as_idx in enumerate(transformer_word_input): # indexing vectorized O(n)\n","      sentence_embed = self.transformer_matrix[sentence_as_idx.cpu()] # sentence_length x embed_hidden_size\n","      batch_embed[i, :, :] = sentence_embed\n","    return torch.from_numpy(batch_embed)\n","\n","\n","  def reset_parameters(self):\n","\n","    for name, param in self.word_lstm.named_parameters():\n","        if 'bias' in name:\n","            nn.init.constant(param, 0.)\n","        elif 'weight' in name:\n","            nn.init.normal(param, mean=0, std=0.1)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"30gGnBfu_LCp","colab_type":"text"},"source":["## CRF"]},{"cell_type":"code","metadata":{"id":"fNJ_5VGC_GhU","colab_type":"code","colab":{}},"source":["def logsumexp(x, dim=None): #AS IS\n","    if dim is None:\n","        xmax = x.max()\n","        xmax_ = x.max()\n","        return xmax_ + torch.log(torch.exp(x - xmax).sum())\n","    else:\n","        xmax, _ = x.max(dim, keepdim=True)\n","        xmax_, _ = x.max(dim)\n","        return xmax_ + torch.log(torch.exp(x - xmax).sum(dim))\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EFCLBuPS_Goq","colab_type":"code","colab":{}},"source":["class CRF_Module(nn.Module):\n","    def __init__(self, input_size, num_labels, bigram=True):\n","\n","\n","        super(CRF_Module, self).__init__()\n","        self.pad_label_id = num_labels\n","        self.bigram = bigram\n","        self.input_size = input_size\n","        self.num_labels = num_labels + 1\n","        self.state_layer = nn.Linear(input_size, self.num_labels)\n","\n","        if bigram: # \n","            self.transition_layer = nn.Linear(input_size, self.num_labels * self.num_labels) # transition weights are learned (costs of moving from one tag to next)\n","            self.register_parameter('transition_matrix', None)\n","        else:\n","            self.transition_layer = None\n","            self.transition_matrix = Parameter(torch.Tensor(self.num_labels, self.num_labels)) # initialize a transition matrix instead \n","\n","        self.reset_parameters()\n","\n","    def forward(self, input, mask=None):\n","      batch, length, _ = input.size()\n","      out_state = self.state_layer(input).unsqueeze(2)\n","\n","      if self.bigram:\n","          out_transition = self.transition_layer(input).view(batch, length, self.num_labels, self.num_labels)\n","          net_output = out_transition + out_state\n","      else:\n","          net_output = self.transition_matrix + out_state\n","\n","      if mask is not None:\n","          net_output = net_output * mask.unsqueeze(2).unsqueeze(3)\n","      return net_output\n","\n","\n","    def reset_parameters(self):\n","      nn.init.constant(self.state_layer.bias, 0.)\n","      if self.bigram:\n","          nn.init.xavier_uniform(self.transition_layer.weight)\n","          nn.init.constant(self.transition_layer.bias, 0.)\n","      else:\n","          nn.init.normal(self.transition_matrix)\n","\n","\n","    def _viterbi_decode(self, input, mask, leading_symbolic=0):\n","      energy = self.forward(input, mask=mask).data\n","      energyTrans = energy.transpose(0, 1) #energy_transpose\n","      energyTrans = energyTrans[:, :, leading_symbolic:-1, leading_symbolic:-1]\n","\n","      w_len, batch_size, num_label, _ = energyTrans.size()\n","      batch_index = torch.arange(0, batch_size).long().cuda()\n","      \n","      curr_mat = torch.zeros([w_len, batch_size, num_label, 1]).cuda()\n","      pointer = torch.cuda.LongTensor(w_len, batch_size, num_label).zero_()\n","      back_pointer = torch.cuda.LongTensor(w_len, batch_size).zero_()\n","\n","      curr_mat[0] = energy[:, 0, -1, leading_symbolic:-1].unsqueeze(2)\n","      pointer[0] = -1\n","      for t in range(1, w_len):\n","          prev_mat = curr_mat[t - 1]\n","          temp_mat, pointer[t] = torch.max(energyTrans[t] + prev_mat, dim=1)\n","          curr_mat[t] = temp_mat.unsqueeze(2)\n","\n","      _, back_pointer[-1] = torch.max(curr_mat[-1].squeeze(2), dim=1)\n","      for t in reversed(range(w_len - 1)):\n","          pointer_last = pointer[t + 1]\n","          back_pointer[t] = pointer_last[batch_index, back_pointer[t + 1]]\n","\n","      return back_pointer.transpose(0, 1) + leading_symbolic\n","\n","    \n","    def loss(self, input, target, mask=None):\n","      #debug()\n","      batch, length, _ = input.size()\n","      energy = self.forward(input, mask=mask)\n","      energy_transpose = energy.transpose(0, 1)\n","      target_transpose = target.transpose(0, 1)\n","      mask_transpose = None\n","      if mask is not None:\n","          mask_transpose = mask.unsqueeze(2).transpose(0, 1)\n","\n","      partition = None\n","\n","      batch_index = torch.arange(0, batch).long().cuda()\n","      prev_label = torch.cuda.LongTensor(batch).fill_(self.num_labels - 1)\n","      tgt_energy = Variable(torch.zeros(batch)).cuda()\n","\n","      for t in range(length):\n","          curr_energy = energy_transpose[t]\n","          if t == 0:\n","              partition = curr_energy[:, -1, :]\n","          else:\n","              partition_new = logsumexp(curr_energy + partition.unsqueeze(2), dim=1)\n","              if mask_transpose is None:\n","                  partition = partition_new\n","              else:\n","                  mask_t = mask_transpose[t]\n","                  partition = partition + (partition_new - partition) * mask_t\n","          tgt_energy += curr_energy[batch_index, prev_label, target_transpose[t].data]\n","          prev_label = target_transpose[t].data\n","\n","      return logsumexp(partition, dim=1) - tgt_energy\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dV2PGV_qee7p","colab_type":"text"},"source":["## wrapper code"]},{"cell_type":"code","metadata":{"id":"bhRc7_sveiB5","colab_type":"code","colab":{}},"source":["class Attention_LSTM_CRF(nn.Module):\n","    def __init__(self, transformer_hidden_size, transformer_matrix, char_vocab_size, char_embed_size, word_vocab_size, word_embedding_size, word_lstm_hiddden_size, word_vector, num_labels, cat_vector=None, cat=0, bigram=True, char_lstm_hidden_size=50):\n","        super(Attention_LSTM_CRF, self).__init__()\n","        self.char_vocab_size = char_vocab_size\n","        self.char_embed_size = char_embed_size\n","        self.word_vocab_size = word_vocab_size\n","        self.word_embedding_size = word_embedding_size\n","        self.word_lstm_hiddden_size = word_lstm_hiddden_size\n","        self.char_lstm_hidden_size = char_lstm_hidden_size\n","        self.word_vector = word_vector\n","        self.transformer_matrix = transformer_matrix\n","        self.transformer_hidden_size = transformer_hidden_size\n","\n","        self.cat = 0\n","        if cat_vector is not None:\n","          self.cat_vector = cat_vector\n","          self.cat_embed = nn.Embedding(word_vocab_size, cat, padding_idx=PAD)\n","          self.cat_embed.weight.data.copy_(torch.from_numpy(np.asarray(cat_vector)))\n","          self.cat = cat\n","\n","        # crf vars\n","        self.num_labels = num_labels\n","        self.bigram = bigram\n","\n","        self.charModel = char_model(self.char_vocab_size, self.char_embed_size, self.char_lstm_hidden_size)\n","        self.Attention = selfAttention(self.transformer_hidden_size, self.transformer_matrix, self.char_lstm_hidden_size, self.word_vocab_size, self.word_embedding_size, self.word_lstm_hiddden_size, self.word_vector)\n","        self.CRF = CRF_Module(self.word_lstm_hiddden_size*4+cat, num_labels)\n","    \n","    def forward(self, transfer_word_input, words, input, word_length, char_input_length, target, hidden=None):\n","        charOut = self.charModel(input, char_input_length) #basically char_hidden_state\n","        AttentionOut = self.Attention(transfer_word_input, words, charOut, word_length)\n","        #Concat with category embedding\n","        if self.cat!=0:\n","          cat_embedding = self.cat_embed(words)\n","          AttentionOut = torch.cat([AttentionOut, cat_embedding], 2)\n","        #debug()\n","        # CRFout = self.CRF(AttentionOut, words.ne(PAD).float()).data # energy\n","\n","        CRFLossOut = self.CRF.loss(AttentionOut, target, words.ne(PAD).float()).mean()\n","        CRFPredict = self.CRF._viterbi_decode(AttentionOut, words.ne(PAD).float(), 1)\n","\n","        return CRFLossOut, CRFPredict\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4_Cf3Dq9QyRZ","colab_type":"text"},"source":["##Training and Validation"]},{"cell_type":"code","metadata":{"id":"8vgUnBcRlkOp","colab_type":"code","colab":{}},"source":["def training(model_save_file, trans_word_vocab_dict, en_to_spanish, char_vocab_dict, model, optimizer, lr, epochs, de_to_spanish=None):\n","  best_f1_score = 0.0\n","  \n","  all_train_loss = []\n","  all_val_loss = []\n","  all_train_acc = []\n","  all_val_acc = []\n","  all_train_f1 = []\n","  all_val_f1 = []\n","\n","  for epoch in range(epochs):\n","      labels_global = []\n","      pred_global = []\n","\n","      model.train()\n","\n","      epoch_loss = 0\n","      total = 0\n","      correct = 0\n","      batch =0\n","      \n","      sentences, OOV, labels = data_to_words_sentences(train_paths, en_to_spanish, False, de_to_spanish) #whole data\n","      \n","      for data in batch_from_data(sentences, OOV, labels, 16):\n","\n","          bsentences, bOOV, y = data\n","          #label_input\n","          \n","          #[bsentences, bOOV] = X\n","          transformer_word_input, word_input, word_length_input, char_input, char_length_input, label_input = get_input(trans_word_vocab_dict, word_to_index, bsentences, bOOV, char_vocab_dict, y, LABEL_INDEX)\n","          optimizer.zero_grad()\n","          true_labels = label_input.contiguous().view(-1)\n","\n","          #forward\n","          loss, predict = model(transformer_word_input, word_input, char_input, word_length_input, char_length_input, label_input)\n","          predict = predict.contiguous().view(-1)\n","\n","          total +=  true_labels.data.ne(PAD).float().sum()\n","          pred_correct = predict.eq(true_labels.data).masked_select(true_labels.ne(PAD).data).float().sum()\n","\n","          loss.backward()\n","          torch.nn.utils.clip_grad_norm(model.parameters(), 5)\n","          optimizer.step()\n","\n","          epoch_loss += loss.item()\n","          correct += pred_correct\n","          batch+=1\n","\n","          labels_global.extend(true_labels.masked_select(true_labels.ne(PAD).data).cpu().data.numpy())\n","          pred_global.extend(predict.masked_select(true_labels.ne(PAD).data).cpu().data.numpy())\n","          \n","          # true_labels_list = list(true_labels.masked_select(true_labels.ne(PAD).data).cpu().data.numpy())\n","          # predict = list(predict.masked_select(true_labels.ne(PAD).data).cpu().data.numpy())\n","          # bsentences = [j for i in bsentences for j in i]\n","          # for i in range(len(bsentences)):\n","          #   print(bsentences[i] + \"\\t\" + LABEL_INDEX[true_labels_list[i]] + \"\\t\" + LABEL_INDEX[predict[i]])\n","\n","          if batch%200==0:\n","            print(\"Batch {} loss: {:.2f}\".format(batch, epoch_loss/batch))\n","    \n","      f1 = f1_score(labels_global, pred_global, average='macro')\n","      \n","      print(\"Epoch {} training loss: {:.4f}, training accuracy: {:.4f}, f1 score {:.2f}\".format(epoch, epoch_loss/batch, correct * 100.0/total, f1))\n","\n","      all_train_loss.append(epoch_loss/batch)\n","      all_train_acc.append(correct * 100.0/total)\n","      all_train_f1.append(f1)\n","\n","      lr = lr / (1.0 + epoch * 0.05) #decay=0.05\n","      for param_group in optimizer.param_groups:\n","          param_group['lr'] = lr\n","      val_f1, val_loss, val_acc = evaluate(trans_word_vocab_dict, en_to_spanish, char_vocab_dict, model, de_to_spanish) # changed signature\n","\n","      all_val_f1.append(val_f1)\n","      all_val_acc.append(val_acc)\n","      all_val_loss.append(val_loss)\n","\n","      # store at best f1\n","      if val_f1 > best_f1_score :\n","        best_f1_score = val_f1\n","        print(\"Saving model on best val F1 so far \" + str(val_f1))\n","        torch.save(model.state_dict(), model_save_file)\n","\n","  return  all_train_loss, all_val_loss , all_train_acc, all_val_acc , all_train_f1 , all_val_f1\n","\n","\n","def evaluate(trans_word_vocab_dict, en_to_spanish, char_vocab_dict, model, de_to_spanish = None):\n","\n","    model.eval()\n","\n","    correct = 0\n","    total = 0\n","    test_loss = 0\n","    batch = 0\n","\n","    labels_global = []\n","    pred_global = []\n","    \n","    sentences, OOV, labels = data_to_words_sentences(val_paths, en_to_spanish, True, de_to_spanish) #whole data\n","\n","    #val_X = [words, OOV]\n","    for data in batch_from_data(sentences, OOV, labels, 16):\n","        \n","        bsentences, bOOV, y = data\n","        #label_input\n","        \n","        #[bsentences, bOOV] = X\n","        \n","        transformer_word_input, word_input, word_length_input, char_input, char_length_input, label_input = get_input(trans_word_vocab_dict, word_to_index, bsentences, bOOV, char_vocab_dict, y, LABEL_INDEX)\n","        loss, predict = model(transformer_word_input, word_input, char_input, word_length_input, char_length_input, label_input)\n","        predict = predict.contiguous().view(-1)\n","        test_loss += loss.item()\n","\n","\n","        true_labels = label_input.contiguous().view(-1)\n","        total += true_labels.data.ne(PAD).float().sum()\n","        pred_correct = predict.eq(true_labels.data).masked_select(true_labels.ne(PAD).data).float().sum()\n","        correct += pred_correct\n","        batch+=1\n","\n","        labels_global.extend(true_labels.masked_select(true_labels.ne(PAD).data).cpu().data.numpy())\n","        pred_global.extend(predict.masked_select(true_labels.ne(PAD).data).cpu().data.numpy())\n","\n","        # true_labels_list = list(true_labels.masked_select(true_labels.ne(PAD).data).cpu().data.numpy())\n","        # predict = list(predict.masked_select(true_labels.ne(PAD).data).cpu().data.numpy())\n","        # bsentences = [j for i in bsentences for j in i]\n","        # for i in range(len(bsentences)):\n","        #   print(bsentences[i] + \"\\t\" + LABEL_INDEX[true_labels_list[i]] + \"\\t\" + LABEL_INDEX[predict[i]])\n","\n","    test_acc = correct * 100.0 / total\n","\n","    f1 = f1_score(labels_global, pred_global, average='macro')\n","\n","    print(\"loss: {:.4f} eval acc: {:.4f} | f1 {:.4f}\".format(test_loss/batch, test_acc, f1))\n","    return f1, test_loss/batch, test_acc\n","\n","def write_to_results(filename, trans_word_vocab_dict, en_to_spanish, char_vocab_dict, model, de_to_spanish=None):\n","\n","    model.eval()\n","\n","    labels_global = []\n","    pred_global = []\n","   \n","    sentences, OOV, labels = data_to_words_sentences(test_paths, en_to_spanish, True, de_to_spanish) #whole data\n","\n","    for data in batch_from_data(sentences, OOV, labels, 16, random=False):\n","        # debug()\n","        bsentences, bOOV, y = data\n","        \n","        transformer_word_input, word_input, word_length_input, char_input, char_length_input, label_input = get_input(trans_word_vocab_dict, word_to_index, bsentences, bOOV, char_vocab_dict, y, LABEL_INDEX)\n","        loss, predict = model(transformer_word_input, word_input, char_input, word_length_input, char_length_input, label_input)\n","        predict = predict.contiguous().view(-1)\n","\n","        true_labels = label_input.contiguous().view(-1)\n","\n","        labels_global.extend(list(true_labels.masked_select(true_labels.ne(PAD).data).cpu().data.numpy()))\n","        pred_global.extend(list(predict.masked_select(true_labels.ne(PAD).data).cpu().data.numpy()))\n","        # true_labels_list = list(true_labels.masked_select(true_labels.ne(PAD).data).cpu().data.numpy())\n","        # predict = list(predict.masked_select(true_labels.ne(PAD).data).cpu().data.numpy())\n","        # bsentences = [j for i in bsentences for j in i]\n","        # for i in range(len(bsentences)):\n","        #   print(bsentences[i] + \"\\t\" + LABEL_INDEX[true_labels_list[i]] + \"\\t\" + LABEL_INDEX[predict[i]])\n","\n","    sentence_tokens = [j for i in sentences for j in i]\n","\n","    with open(filename, \"w\") as f:\n","        for i in range(len(sentence_tokens)):\n","            f.write(sentence_tokens[i] + \"\\t\" + LABEL_INDEX[labels_global[i]] + \"\\t\" + LABEL_INDEX[pred_global[i]] + \"\\n\")\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IoY8DwYOb3Cf","colab_type":"text"},"source":["#Training and Evaluating"]},{"cell_type":"markdown","metadata":{"id":"gRB0YA1ub-pa","colab_type":"text"},"source":["##Loading data"]},{"cell_type":"code","metadata":{"id":"Hw6pjcq95im4","colab_type":"code","outputId":"27595a58-528c-4a1f-95e0-70438f1c8ca5","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["cd /content/gdrive/Shared drives/CIS 530 Project"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content/gdrive/Shared drives/CIS 530 Project\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Z8Oc394u5D6n","colab_type":"code","outputId":"40cd0b08-0c31-4537-83a5-a3587783fdad","executionInfo":{"status":"ok","timestamp":1588341261151,"user_tz":240,"elapsed":65333,"user":{"displayName":"John Zhang","photoUrl":"","userId":"12653864259381014680"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# spanish.glove.gigaword_wiki.100d.magnitude\n","embedding_path = \"spanish.glove.gigaword_wiki.100d.magnitude\"\n","\n","path = \"translations_bi.txt\"\n","de_es_translation_dict = None\n","if use_de: \n","  embedding_path = \"umwe-esp-smallish.magnitude\"\n","  de_es_translation_dict = language_to_spanish_dict(\"translations_umwe_ned.txt\")\n","  path = \"translations_umwe_eng.txt\"\n","en_es_translation_dict = language_to_spanish_dict(path)\n","all_paths=[]\n","all_paths.extend(train_paths)\n","all_paths.extend(val_paths)\n","all_paths.extend(test_paths)  \n","char_vocab_dict = create_char_index(all_paths, en_es_translation_dict, False, de_es_translation_dict)\n","matrix, word_to_index = get_indexed_word_embeddings(en_es_translation_dict, embedding_path, de_es_translation_dict) #word_vector, word_\n","\n","matrix = np.ones((matrix.shape[0], 1))\n","\n","# change model name, generate results below\n","global model_save_file \n","model_save_file=\"CombinationBestV4\" \n","global results_save_file\n","results_save_file = \"results_combination_4.txt\"\n","\n","transformer_matrix, trans_word_vocab_dict = get_indexed_mbert_word_embeddings()\n","\n","use_distances = True\n","\n","extraInfo = None\n","numCat = 0\n","if use_distances:\n","  # change to True to use distances to category means, False to use ratio of previous distributions\n","  extraInfo = get_distributional_info(transformer_matrix, trans_word_vocab_dict, en_es_translation_dict, True, de_es_translation_dict)\n","  numCat = len(CAT) + 1\n","\n","transformer_matrix = np.concatenate((transformer_matrix, extraInfo), axis = 1)\n","\n","transformer_hidden_size = transformer_matrix.shape[1]\n","# transformer_matrix_tensor = torch.from_numpy(transformer_matrix)\n","\n","print(transformer_hidden_size)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["773\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"qLPDlaYkb4g2","colab_type":"text"},"source":["## Training"]},{"cell_type":"code","metadata":{"id":"ZqsWcyRUFT6U","colab_type":"code","outputId":"80f0d986-8bd0-4d6b-c66c-eabc5392fe6d","executionInfo":{"status":"ok","timestamp":1588352396499,"user_tz":240,"elapsed":10053246,"user":{"displayName":"John Zhang","photoUrl":"","userId":"12653864259381014680"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["\n","# model init call\n","model = Attention_LSTM_CRF(transformer_hidden_size, transformer_matrix, len(char_vocab_dict), 25, len(matrix), 1, 200, matrix, len(LABEL_INDEX), None, 0).cuda()\n","optimizer = torch.optim.SGD(model.parameters(), lr=0.015, momentum=0.9, weight_decay=1e-4)\n","#optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","\n","\n","all_train_loss, all_val_loss , all_train_acc, all_val_acc , all_train_f1 , all_val_f1 = training(model_save_file, trans_word_vocab_dict, en_es_translation_dict, char_vocab_dict, model, optimizer, 0.015, 30, de_es_translation_dict)\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:37: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:39: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:40: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:42: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n"],"name":"stderr"},{"output_type":"stream","text":["Batch 200 loss: 5.94\n","Batch 400 loss: 4.77\n","Batch 600 loss: 4.06\n","Batch 800 loss: 3.62\n","Batch 1000 loss: 3.30\n","Batch 1200 loss: 3.08\n","Batch 1400 loss: 2.90\n","Batch 1600 loss: 2.77\n","Batch 1800 loss: 2.66\n","Batch 2000 loss: 2.57\n","Batch 2200 loss: 2.49\n","Batch 2400 loss: 2.41\n","Batch 2600 loss: 2.36\n","Epoch 0 training loss: 2.3057, training accuracy: 93.3108, f1 score 0.57\n","loss: 3.8749 eval acc: 93.1863 | f1 0.5537\n","Saving model on best val F1 so far 0.5537010964725727\n","Batch 200 loss: 1.57\n","Batch 400 loss: 1.54\n","Batch 600 loss: 1.54\n","Batch 800 loss: 1.52\n","Batch 1000 loss: 1.50\n","Batch 1200 loss: 1.51\n","Batch 1400 loss: 1.50\n","Batch 1600 loss: 1.49\n","Batch 1800 loss: 1.49\n","Batch 2000 loss: 1.48\n","Batch 2200 loss: 1.46\n","Batch 2400 loss: 1.46\n","Batch 2600 loss: 1.45\n","Epoch 1 training loss: 1.4378, training accuracy: 95.4882, f1 score 0.69\n","loss: 3.7087 eval acc: 93.7211 | f1 0.5822\n","Saving model on best val F1 so far 0.5821812840707743\n","Batch 200 loss: 1.29\n","Batch 400 loss: 1.36\n","Batch 600 loss: 1.32\n","Batch 800 loss: 1.33\n","Batch 1000 loss: 1.32\n","Batch 1200 loss: 1.29\n","Batch 1400 loss: 1.28\n","Batch 1600 loss: 1.27\n","Batch 1800 loss: 1.26\n","Batch 2000 loss: 1.26\n","Batch 2200 loss: 1.25\n","Batch 2400 loss: 1.25\n","Batch 2600 loss: 1.24\n","Epoch 2 training loss: 1.2361, training accuracy: 96.0905, f1 score 0.73\n","loss: 3.4180 eval acc: 94.1840 | f1 0.6078\n","Saving model on best val F1 so far 0.6078316289180202\n","Batch 200 loss: 1.14\n","Batch 400 loss: 1.13\n","Batch 600 loss: 1.12\n","Batch 800 loss: 1.13\n","Batch 1000 loss: 1.12\n","Batch 1200 loss: 1.12\n","Batch 1400 loss: 1.13\n","Batch 1600 loss: 1.12\n","Batch 1800 loss: 1.11\n","Batch 2000 loss: 1.11\n","Batch 2200 loss: 1.11\n","Batch 2400 loss: 1.10\n","Batch 2600 loss: 1.11\n","Epoch 3 training loss: 1.1133, training accuracy: 96.4761, f1 score 0.75\n","loss: 3.4539 eval acc: 94.5449 | f1 0.6368\n","Saving model on best val F1 so far 0.6367798565308386\n","Batch 200 loss: 1.03\n","Batch 400 loss: 1.02\n","Batch 600 loss: 1.02\n","Batch 800 loss: 1.02\n","Batch 1000 loss: 1.01\n","Batch 1200 loss: 1.03\n","Batch 1400 loss: 1.02\n","Batch 1600 loss: 1.02\n","Batch 1800 loss: 1.02\n","Batch 2000 loss: 1.02\n","Batch 2200 loss: 1.01\n","Batch 2400 loss: 1.02\n","Batch 2600 loss: 1.01\n","Epoch 4 training loss: 1.0102, training accuracy: 96.7955, f1 score 0.78\n","loss: 3.2629 eval acc: 94.4410 | f1 0.6275\n","Batch 200 loss: 0.93\n","Batch 400 loss: 0.93\n","Batch 600 loss: 0.95\n","Batch 800 loss: 0.94\n","Batch 1000 loss: 0.95\n","Batch 1200 loss: 0.94\n","Batch 1400 loss: 0.94\n","Batch 1600 loss: 0.94\n","Batch 1800 loss: 0.94\n","Batch 2000 loss: 0.94\n","Batch 2200 loss: 0.94\n","Batch 2400 loss: 0.94\n","Batch 2600 loss: 0.94\n","Epoch 5 training loss: 0.9341, training accuracy: 96.9732, f1 score 0.79\n","loss: 3.2447 eval acc: 94.7244 | f1 0.6329\n","Batch 200 loss: 0.91\n","Batch 400 loss: 0.90\n","Batch 600 loss: 0.88\n","Batch 800 loss: 0.87\n","Batch 1000 loss: 0.88\n","Batch 1200 loss: 0.89\n","Batch 1400 loss: 0.90\n","Batch 1600 loss: 0.89\n","Batch 1800 loss: 0.89\n","Batch 2000 loss: 0.89\n","Batch 2200 loss: 0.88\n","Batch 2400 loss: 0.87\n","Batch 2600 loss: 0.87\n","Epoch 6 training loss: 0.8676, training accuracy: 97.2360, f1 score 0.81\n","loss: 3.2712 eval acc: 94.5166 | f1 0.6361\n","Batch 200 loss: 0.77\n","Batch 400 loss: 0.79\n","Batch 600 loss: 0.81\n","Batch 800 loss: 0.80\n","Batch 1000 loss: 0.81\n","Batch 1200 loss: 0.81\n","Batch 1400 loss: 0.81\n","Batch 1600 loss: 0.81\n","Batch 1800 loss: 0.81\n","Batch 2000 loss: 0.81\n","Batch 2200 loss: 0.81\n","Batch 2400 loss: 0.81\n","Batch 2600 loss: 0.81\n","Epoch 7 training loss: 0.8108, training accuracy: 97.3926, f1 score 0.82\n","loss: 3.5314 eval acc: 93.8477 | f1 0.6087\n","Batch 200 loss: 0.76\n","Batch 400 loss: 0.76\n","Batch 600 loss: 0.76\n","Batch 800 loss: 0.76\n","Batch 1000 loss: 0.76\n","Batch 1200 loss: 0.75\n","Batch 1400 loss: 0.75\n","Batch 1600 loss: 0.76\n","Batch 1800 loss: 0.76\n","Batch 2000 loss: 0.76\n","Batch 2200 loss: 0.76\n","Batch 2400 loss: 0.76\n","Batch 2600 loss: 0.77\n","Epoch 8 training loss: 0.7662, training accuracy: 97.5436, f1 score 0.83\n","loss: 3.4413 eval acc: 94.3484 | f1 0.6467\n","Saving model on best val F1 so far 0.6467135455564311\n","Batch 200 loss: 0.71\n","Batch 400 loss: 0.73\n","Batch 600 loss: 0.73\n","Batch 800 loss: 0.73\n","Batch 1000 loss: 0.73\n","Batch 1200 loss: 0.72\n","Batch 1400 loss: 0.73\n","Batch 1600 loss: 0.73\n","Batch 1800 loss: 0.73\n","Batch 2000 loss: 0.73\n","Batch 2200 loss: 0.73\n","Batch 2400 loss: 0.73\n","Batch 2600 loss: 0.73\n","Epoch 9 training loss: 0.7316, training accuracy: 97.6382, f1 score 0.84\n","loss: 3.2013 eval acc: 95.0173 | f1 0.6756\n","Saving model on best val F1 so far 0.6756139437014917\n","Batch 200 loss: 0.76\n","Batch 400 loss: 0.72\n","Batch 600 loss: 0.73\n","Batch 800 loss: 0.71\n","Batch 1000 loss: 0.72\n","Batch 1200 loss: 0.72\n","Batch 1400 loss: 0.72\n","Batch 1600 loss: 0.71\n","Batch 1800 loss: 0.71\n","Batch 2000 loss: 0.71\n","Batch 2200 loss: 0.71\n","Batch 2400 loss: 0.71\n","Batch 2600 loss: 0.71\n","Epoch 10 training loss: 0.7094, training accuracy: 97.7028, f1 score 0.84\n","loss: 3.2677 eval acc: 94.7206 | f1 0.6421\n","Batch 200 loss: 0.73\n","Batch 400 loss: 0.71\n","Batch 600 loss: 0.71\n","Batch 800 loss: 0.70\n","Batch 1000 loss: 0.70\n","Batch 1200 loss: 0.70\n","Batch 1400 loss: 0.70\n","Batch 1600 loss: 0.69\n","Batch 1800 loss: 0.69\n","Batch 2000 loss: 0.69\n","Batch 2200 loss: 0.69\n","Batch 2400 loss: 0.69\n","Batch 2600 loss: 0.69\n","Epoch 11 training loss: 0.6936, training accuracy: 97.7694, f1 score 0.85\n","loss: 3.3946 eval acc: 94.8378 | f1 0.6549\n","Batch 200 loss: 0.66\n","Batch 400 loss: 0.65\n","Batch 600 loss: 0.65\n","Batch 800 loss: 0.66\n","Batch 1000 loss: 0.66\n","Batch 1200 loss: 0.67\n","Batch 1400 loss: 0.67\n","Batch 1600 loss: 0.67\n","Batch 1800 loss: 0.67\n","Batch 2000 loss: 0.67\n","Batch 2200 loss: 0.67\n","Batch 2400 loss: 0.67\n","Batch 2600 loss: 0.67\n","Epoch 12 training loss: 0.6765, training accuracy: 97.8033, f1 score 0.85\n","loss: 3.2707 eval acc: 95.0532 | f1 0.6723\n","Batch 200 loss: 0.65\n","Batch 400 loss: 0.65\n","Batch 600 loss: 0.67\n","Batch 800 loss: 0.67\n","Batch 1000 loss: 0.67\n","Batch 1200 loss: 0.68\n","Batch 1400 loss: 0.68\n","Batch 1600 loss: 0.67\n","Batch 1800 loss: 0.67\n","Batch 2000 loss: 0.67\n","Batch 2200 loss: 0.67\n","Batch 2400 loss: 0.67\n","Batch 2600 loss: 0.67\n","Epoch 13 training loss: 0.6675, training accuracy: 97.8311, f1 score 0.85\n","loss: 3.2756 eval acc: 94.9606 | f1 0.6633\n","Batch 200 loss: 0.69\n","Batch 400 loss: 0.70\n","Batch 600 loss: 0.69\n","Batch 800 loss: 0.69\n","Batch 1000 loss: 0.68\n","Batch 1200 loss: 0.67\n","Batch 1400 loss: 0.67\n","Batch 1600 loss: 0.67\n","Batch 1800 loss: 0.67\n","Batch 2000 loss: 0.67\n","Batch 2200 loss: 0.67\n","Batch 2400 loss: 0.67\n","Batch 2600 loss: 0.67\n","Epoch 14 training loss: 0.6658, training accuracy: 97.8598, f1 score 0.85\n","loss: 3.2904 eval acc: 94.9360 | f1 0.6573\n","Batch 200 loss: 0.67\n","Batch 400 loss: 0.66\n","Batch 600 loss: 0.66\n","Batch 800 loss: 0.66\n","Batch 1000 loss: 0.66\n","Batch 1200 loss: 0.67\n","Batch 1400 loss: 0.67\n","Batch 1600 loss: 0.66\n","Batch 1800 loss: 0.66\n","Batch 2000 loss: 0.66\n","Batch 2200 loss: 0.66\n","Batch 2400 loss: 0.66\n","Batch 2600 loss: 0.67\n","Epoch 15 training loss: 0.6642, training accuracy: 97.8797, f1 score 0.85\n","loss: 3.3224 eval acc: 94.9927 | f1 0.6610\n","Batch 200 loss: 0.71\n","Batch 400 loss: 0.67\n","Batch 600 loss: 0.65\n","Batch 800 loss: 0.65\n","Batch 1000 loss: 0.64\n","Batch 1200 loss: 0.64\n","Batch 1400 loss: 0.65\n","Batch 1600 loss: 0.65\n","Batch 1800 loss: 0.65\n","Batch 2000 loss: 0.65\n","Batch 2200 loss: 0.65\n","Batch 2400 loss: 0.65\n","Batch 2600 loss: 0.65\n","Epoch 16 training loss: 0.6556, training accuracy: 97.9035, f1 score 0.86\n","loss: 3.3102 eval acc: 94.9530 | f1 0.6612\n","Batch 200 loss: 0.66\n","Batch 400 loss: 0.68\n","Batch 600 loss: 0.67\n","Batch 800 loss: 0.67\n","Batch 1000 loss: 0.67\n","Batch 1200 loss: 0.67\n","Batch 1400 loss: 0.66\n","Batch 1600 loss: 0.66\n","Batch 1800 loss: 0.66\n","Batch 2000 loss: 0.66\n","Batch 2200 loss: 0.65\n","Batch 2400 loss: 0.65\n","Batch 2600 loss: 0.65\n","Epoch 17 training loss: 0.6500, training accuracy: 97.9151, f1 score 0.86\n","loss: 3.3101 eval acc: 94.9493 | f1 0.6605\n","Batch 200 loss: 0.67\n","Batch 400 loss: 0.66\n","Batch 600 loss: 0.67\n","Batch 800 loss: 0.67\n","Batch 1000 loss: 0.66\n","Batch 1200 loss: 0.66\n","Batch 1400 loss: 0.66\n","Batch 1600 loss: 0.65\n","Batch 1800 loss: 0.65\n","Batch 2000 loss: 0.65\n","Batch 2200 loss: 0.65\n","Batch 2400 loss: 0.65\n","Batch 2600 loss: 0.65\n","Epoch 18 training loss: 0.6528, training accuracy: 97.9058, f1 score 0.86\n","loss: 3.2973 eval acc: 95.0116 | f1 0.6644\n","Batch 200 loss: 0.62\n","Batch 400 loss: 0.62\n","Batch 600 loss: 0.63\n","Batch 800 loss: 0.65\n","Batch 1000 loss: 0.64\n","Batch 1200 loss: 0.64\n","Batch 1400 loss: 0.64\n","Batch 1600 loss: 0.65\n","Batch 1800 loss: 0.65\n","Batch 2000 loss: 0.65\n","Batch 2200 loss: 0.65\n","Batch 2400 loss: 0.65\n","Batch 2600 loss: 0.65\n","Epoch 19 training loss: 0.6555, training accuracy: 97.8675, f1 score 0.85\n","loss: 3.3063 eval acc: 95.0041 | f1 0.6635\n","Batch 200 loss: 0.64\n","Batch 400 loss: 0.64\n","Batch 600 loss: 0.64\n","Batch 800 loss: 0.64\n","Batch 1000 loss: 0.64\n","Batch 1200 loss: 0.63\n","Batch 1400 loss: 0.64\n","Batch 1600 loss: 0.64\n","Batch 1800 loss: 0.65\n","Batch 2000 loss: 0.65\n","Batch 2200 loss: 0.65\n","Batch 2400 loss: 0.65\n","Batch 2600 loss: 0.66\n","Epoch 20 training loss: 0.6549, training accuracy: 97.8732, f1 score 0.85\n","loss: 3.3031 eval acc: 95.0060 | f1 0.6638\n","Batch 200 loss: 0.66\n","Batch 400 loss: 0.66\n","Batch 600 loss: 0.66\n","Batch 800 loss: 0.65\n","Batch 1000 loss: 0.66\n","Batch 1200 loss: 0.65\n","Batch 1400 loss: 0.65\n","Batch 1600 loss: 0.65\n","Batch 1800 loss: 0.66\n","Batch 2000 loss: 0.66\n","Batch 2200 loss: 0.66\n","Batch 2400 loss: 0.66\n","Batch 2600 loss: 0.66\n","Epoch 21 training loss: 0.6558, training accuracy: 97.9036, f1 score 0.86\n","loss: 3.3007 eval acc: 94.9984 | f1 0.6632\n","Batch 200 loss: 0.63\n","Batch 400 loss: 0.65\n","Batch 600 loss: 0.66\n","Batch 800 loss: 0.67\n","Batch 1000 loss: 0.67\n","Batch 1200 loss: 0.65\n","Batch 1400 loss: 0.65\n","Batch 1600 loss: 0.66\n","Batch 1800 loss: 0.66\n","Batch 2000 loss: 0.66\n","Batch 2200 loss: 0.66\n","Batch 2400 loss: 0.65\n","Batch 2600 loss: 0.65\n","Epoch 22 training loss: 0.6548, training accuracy: 97.9004, f1 score 0.86\n","loss: 3.3104 eval acc: 95.0060 | f1 0.6639\n","Batch 200 loss: 0.66\n","Batch 400 loss: 0.66\n","Batch 600 loss: 0.65\n","Batch 800 loss: 0.64\n","Batch 1000 loss: 0.65\n","Batch 1200 loss: 0.65\n","Batch 1400 loss: 0.65\n","Batch 1600 loss: 0.65\n","Batch 1800 loss: 0.65\n","Batch 2000 loss: 0.65\n","Batch 2200 loss: 0.66\n","Batch 2400 loss: 0.65\n","Batch 2600 loss: 0.65\n","Epoch 23 training loss: 0.6563, training accuracy: 97.8789, f1 score 0.85\n","loss: 3.3096 eval acc: 95.0097 | f1 0.6639\n","Batch 200 loss: 0.65\n","Batch 400 loss: 0.64\n","Batch 600 loss: 0.64\n","Batch 800 loss: 0.64\n","Batch 1000 loss: 0.63\n","Batch 1200 loss: 0.63\n","Batch 1400 loss: 0.64\n","Batch 1600 loss: 0.64\n","Batch 1800 loss: 0.64\n","Batch 2000 loss: 0.65\n","Batch 2200 loss: 0.65\n","Batch 2400 loss: 0.65\n","Batch 2600 loss: 0.65\n","Epoch 24 training loss: 0.6530, training accuracy: 97.9041, f1 score 0.86\n","loss: 3.3025 eval acc: 95.0173 | f1 0.6641\n","Batch 200 loss: 0.63\n","Batch 400 loss: 0.62\n","Batch 600 loss: 0.64\n","Batch 800 loss: 0.63\n","Batch 1000 loss: 0.64\n","Batch 1200 loss: 0.65\n","Batch 1400 loss: 0.64\n","Batch 1600 loss: 0.64\n","Batch 1800 loss: 0.65\n","Batch 2000 loss: 0.65\n","Batch 2200 loss: 0.65\n","Batch 2400 loss: 0.65\n","Batch 2600 loss: 0.65\n","Epoch 25 training loss: 0.6539, training accuracy: 97.8938, f1 score 0.86\n","loss: 3.2998 eval acc: 95.0116 | f1 0.6640\n","Batch 200 loss: 0.63\n","Batch 400 loss: 0.65\n","Batch 600 loss: 0.65\n","Batch 800 loss: 0.64\n","Batch 1000 loss: 0.64\n","Batch 1200 loss: 0.64\n","Batch 1400 loss: 0.64\n","Batch 1600 loss: 0.64\n","Batch 1800 loss: 0.64\n","Batch 2000 loss: 0.64\n","Batch 2200 loss: 0.65\n","Batch 2400 loss: 0.65\n","Batch 2600 loss: 0.65\n","Epoch 26 training loss: 0.6499, training accuracy: 97.9049, f1 score 0.86\n","loss: 3.3000 eval acc: 95.0211 | f1 0.6650\n","Batch 200 loss: 0.71\n","Batch 400 loss: 0.68\n","Batch 600 loss: 0.66\n","Batch 800 loss: 0.65\n","Batch 1000 loss: 0.64\n","Batch 1200 loss: 0.63\n","Batch 1400 loss: 0.63\n","Batch 1600 loss: 0.64\n","Batch 1800 loss: 0.65\n","Batch 2000 loss: 0.65\n","Batch 2200 loss: 0.65\n","Batch 2400 loss: 0.65\n","Batch 2600 loss: 0.65\n","Epoch 27 training loss: 0.6528, training accuracy: 97.9131, f1 score 0.86\n","loss: 3.3036 eval acc: 95.0211 | f1 0.6649\n","Batch 200 loss: 0.70\n","Batch 400 loss: 0.69\n","Batch 600 loss: 0.69\n","Batch 800 loss: 0.68\n","Batch 1000 loss: 0.67\n","Batch 1200 loss: 0.67\n","Batch 1400 loss: 0.66\n","Batch 1600 loss: 0.66\n","Batch 1800 loss: 0.66\n","Batch 2000 loss: 0.66\n","Batch 2200 loss: 0.66\n","Batch 2400 loss: 0.65\n","Batch 2600 loss: 0.65\n","Epoch 28 training loss: 0.6522, training accuracy: 97.9170, f1 score 0.86\n","loss: 3.3106 eval acc: 95.0135 | f1 0.6639\n","Batch 200 loss: 0.64\n","Batch 400 loss: 0.65\n","Batch 600 loss: 0.66\n","Batch 800 loss: 0.67\n","Batch 1000 loss: 0.66\n","Batch 1200 loss: 0.66\n","Batch 1400 loss: 0.66\n","Batch 1600 loss: 0.66\n","Batch 1800 loss: 0.66\n","Batch 2000 loss: 0.66\n","Batch 2200 loss: 0.66\n","Batch 2400 loss: 0.66\n","Batch 2600 loss: 0.66\n","Epoch 29 training loss: 0.6568, training accuracy: 97.8725, f1 score 0.85\n","loss: 3.3070 eval acc: 95.0116 | f1 0.6639\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"0iA9mq4rcFi3","colab_type":"text"},"source":["##saving model"]},{"cell_type":"markdown","metadata":{"id":"kaLzuUxG3h4d","colab_type":"text"},"source":["## Open model and write to results"]},{"cell_type":"code","metadata":{"id":"JcB4w59H3deH","colab_type":"code","colab":{}},"source":["\n","# model = Attention_LSTM_CRF(transformer_hidden_size, transformer_matrix, len(char_vocab_dict), 25, len(matrix), 300, 200, matrix, len(LABEL_INDEX), None, 0).cuda()\n","# model.load_state_dict(torch.load(model_save_file))\n","\n","write_to_results(results_save_file, trans_word_vocab_dict, en_es_translation_dict, char_vocab_dict, model, de_es_translation_dict)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FfcwqjTKuUzV","colab_type":"code","colab":{}},"source":["  mat, trans_word_vocab_dict = get_indexed_mbert_word_embeddings()\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LHiaR1opuVW8","colab_type":"code","outputId":"9a229900-9934-435b-e8d5-a1b917cae0d4","colab":{"base_uri":"https://localhost:8080/","height":50}},"source":["embed = mat[trans_word_vocab_dict.get('cat')]\n","print(embed.shape)\n","print(type(embed))\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(768,)\n","<class 'numpy.ndarray'>\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Mw2KkMMGuXS5","colab_type":"code","colab":{}},"source":["function ClickConnect(){ console.log(\"Working\"); document.querySelector(\"colab-toolbar-button\").click() }setInterval(ClickConnect,6000000)"],"execution_count":0,"outputs":[]}]}